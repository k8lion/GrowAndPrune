{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: torch in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (0.14.1)\n",
      "Requirement already satisfied: transformers in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 4)) (4.25.1)\n",
      "Requirement already satisfied: typing-extensions in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from torch->-r ../requirements.txt (line 2)) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from torch->-r ../requirements.txt (line 2)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from torch->-r ../requirements.txt (line 2)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from torch->-r ../requirements.txt (line 2)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from torch->-r ../requirements.txt (line 2)) (11.7.99)\n",
      "Requirement already satisfied: wheel in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r ../requirements.txt (line 2)) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r ../requirements.txt (line 2)) (63.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from torchvision->-r ../requirements.txt (line 3)) (9.4.0)\n",
      "Requirement already satisfied: requests in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from torchvision->-r ../requirements.txt (line 3)) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from transformers->-r ../requirements.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from transformers->-r ../requirements.txt (line 4)) (0.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from transformers->-r ../requirements.txt (line 4)) (22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from transformers->-r ../requirements.txt (line 4)) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from transformers->-r ../requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from transformers->-r ../requirements.txt (line 4)) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from transformers->-r ../requirements.txt (line 4)) (3.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from requests->torchvision->-r ../requirements.txt (line 3)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from requests->torchvision->-r ../requirements.txt (line 3)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from requests->torchvision->-r ../requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages (from requests->torchvision->-r ../requirements.txt (line 3)) (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/kaitlin/repos/NeurOps/pytorch/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.expanduser(\"~/repos/NeurOps/pytorch\"))\n",
    "from neurops import *\n",
    "\n",
    "from growprune import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 1090 effective parameters.\n"
     ]
    }
   ],
   "source": [
    "hidden = [16]\n",
    "regression = False\n",
    "\n",
    "base_data = ToyData(64, 32, 5000, regression=regression)\n",
    "train_loader, val_loader, test_loader = split_dataset(base_data, val_size = 0.1, test_size = 0.1, batch_size = 128)\n",
    "\n",
    "\n",
    "\n",
    "model = ModSequential(\n",
    "        ModLinear(64, hidden[0], masked=True, prebatchnorm=True, learnable_mask=True),\n",
    "        #ModLinear(hidden[0], hidden[1], masked=True, prebatchnorm=True, learnable_mask=True),\n",
    "        ModLinear(hidden[0], 1 if regression else 2, masked=True, prebatchnorm=True),\n",
    "        track_activations=True,\n",
    "        track_auxiliary_gradients=True\n",
    "    ).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss() if regression else torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"This model has {} effective parameters.\".format(model.parameter_count(masked = True)))\n",
    "#print(\"The conversion factor of this model is {} after layer {}.\".format(model.conversion_factor, model.conversion_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Average loss: 0.0062, Accuracy: 232/450 (51.56%)\n",
      "Validation: Average loss: 0.0060, Accuracy: 263/450 (58.44%)\n",
      "Validation: Average loss: 0.0056, Accuracy: 286/450 (63.56%)\n",
      "Validation: Average loss: 0.0053, Accuracy: 316/450 (70.22%)\n",
      "Validation: Average loss: 0.0050, Accuracy: 333/450 (74.00%)\n",
      "Validation: Average loss: 0.0047, Accuracy: 349/450 (77.56%)\n",
      "Validation: Average loss: 0.0044, Accuracy: 361/450 (80.22%)\n",
      "Validation: Average loss: 0.0040, Accuracy: 376/450 (83.56%)\n",
      "Validation: Average loss: 0.0037, Accuracy: 384/450 (85.33%)\n",
      "Validation: Average loss: 0.0034, Accuracy: 397/450 (88.22%)\n",
      "Validation: Average loss: 0.0030, Accuracy: 400/450 (88.89%)\n",
      "Validation: Average loss: 0.0029, Accuracy: 406/450 (90.22%)\n",
      "Validation: Average loss: 0.0026, Accuracy: 409/450 (90.89%)\n",
      "Validation: Average loss: 0.0025, Accuracy: 414/450 (92.00%)\n",
      "Validation: Average loss: 0.0022, Accuracy: 413/450 (91.78%)\n",
      "Validation: Average loss: 0.0021, Accuracy: 416/450 (92.44%)\n",
      "Validation: Average loss: 0.0019, Accuracy: 419/450 (93.11%)\n",
      "Validation: Average loss: 0.0018, Accuracy: 421/450 (93.56%)\n",
      "Validation: Average loss: 0.0017, Accuracy: 421/450 (93.56%)\n",
      "Validation: Average loss: 0.0015, Accuracy: 423/450 (94.00%)\n",
      "Validation: Average loss: 0.0015, Accuracy: 424/450 (94.22%)\n",
      "Validation: Average loss: 0.0014, Accuracy: 428/450 (95.11%)\n",
      "Validation: Average loss: 0.0013, Accuracy: 429/450 (95.33%)\n",
      "Validation: Average loss: 0.0013, Accuracy: 429/450 (95.33%)\n",
      "Validation: Average loss: 0.0012, Accuracy: 429/450 (95.33%)\n",
      "Validation: Average loss: 0.0011, Accuracy: 431/450 (95.78%)\n",
      "Validation: Average loss: 0.0011, Accuracy: 431/450 (95.78%)\n",
      "Validation: Average loss: 0.0010, Accuracy: 431/450 (95.78%)\n",
      "Validation: Average loss: 0.0010, Accuracy: 433/450 (96.22%)\n",
      "Validation: Average loss: 0.0010, Accuracy: 433/450 (96.22%)\n",
      "Validation: Average loss: 0.0010, Accuracy: 435/450 (96.67%)\n",
      "Validation: Average loss: 0.0009, Accuracy: 438/450 (97.33%)\n",
      "Validation: Average loss: 0.0009, Accuracy: 438/450 (97.33%)\n",
      "Validation: Average loss: 0.0009, Accuracy: 438/450 (97.33%)\n",
      "Validation: Average loss: 0.0008, Accuracy: 438/450 (97.33%)\n",
      "Validation: Average loss: 0.0008, Accuracy: 438/450 (97.33%)\n",
      "Validation: Average loss: 0.0008, Accuracy: 438/450 (97.33%)\n",
      "Validation: Average loss: 0.0008, Accuracy: 437/450 (97.11%)\n",
      "Validation: Average loss: 0.0008, Accuracy: 438/450 (97.33%)\n",
      "Validation: Average loss: 0.0007, Accuracy: 437/450 (97.11%)\n",
      "Validation: Average loss: 0.0007, Accuracy: 439/450 (97.56%)\n",
      "Validation: Average loss: 0.0007, Accuracy: 439/450 (97.56%)\n",
      "Validation: Average loss: 0.0007, Accuracy: 439/450 (97.56%)\n",
      "Validation: Average loss: 0.0006, Accuracy: 439/450 (97.56%)\n",
      "Validation: Average loss: 0.0007, Accuracy: 440/450 (97.78%)\n",
      "Validation: Average loss: 0.0006, Accuracy: 441/450 (98.00%)\n",
      "Validation: Average loss: 0.0006, Accuracy: 440/450 (97.78%)\n",
      "Validation: Average loss: 0.0006, Accuracy: 440/450 (97.78%)\n",
      "Validation: Average loss: 0.0006, Accuracy: 441/450 (98.00%)\n",
      "Validation: Average loss: 0.0005, Accuracy: 441/450 (98.00%)\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, optimizer, criterion, epochs=50, val_loader=val_loader, device=device, regression=regression, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modded_data = copy.deepcopy(base_data)\n",
    "#modded_data.shift_distribution(-1, 100)\n",
    "#modded_train_loader, modded_val_loader, modded_test_loader = split_dataset(modded_data, val_size = 0.1, test_size = 0.1, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 32 epochs per shift, shifting window by 32 indices 2 times\n",
      "32, 64, \n",
      "Average loss: 0.0008, Accuracy: 444/450 (98.67%), -1: 148.015 10166317.0\t0: 28.277 43937.9\t1: 8.515 1347.2\t\n",
      "Average loss: 0.0189, Accuracy: 221/450 (49.11%), -1: 148.130 10210169.0\t0: 28.004 50654.9\t1: 8.138 10382.8\t\n",
      "Average loss: 0.0008, Accuracy: 441/450 (98.00%), -1: 148.852 10539375.0\t0: 27.776 39788.4\t1: 10.518 3725.8\t\n",
      "Training 16 epochs per shift, shifting window by 16 indices 4 times\n",
      "16, 32, 48, 64, \n",
      "Average loss: 0.0015, Accuracy: 429/450 (95.33%), -1: 148.714 10591118.0\t0: 28.004 50568.9\t1: 10.826 6668.9\t\n",
      "Average loss: 0.0069, Accuracy: 318/450 (70.67%), -1: 147.760 10009573.0\t0: 27.281 30148.9\t1: 7.761 999.8\t\n",
      "Average loss: 0.0136, Accuracy: 224/450 (49.78%), -1: 149.591 10602417.0\t0: 28.854 51539.3\t1: 9.059 2616.2\t\n",
      "Average loss: 0.0061, Accuracy: 325/450 (72.22%), -1: 148.683 10388355.0\t0: 27.377 32574.0\t1: 6.402 335.0\t\n",
      "Average loss: 0.0014, Accuracy: 429/450 (95.33%), -1: 149.429 10691659.0\t0: 27.975 42013.5\t1: 9.163 1861.9\t\n",
      "Training 8 epochs per shift, shifting window by 8 indices 8 times\n",
      "8, 16, 24, 32, 40, 48, 56, 64, \n",
      "Average loss: 0.0024, Accuracy: 391/450 (86.89%), -1: 147.904 10094937.0\t0: 26.654 21205.8\t1: 6.301 559.2\t\n",
      "Average loss: 0.0045, Accuracy: 346/450 (76.89%), -1: 148.707 10384419.0\t0: 26.410 26228.1\t1: 6.197 1043.8\t\n",
      "Average loss: 0.0068, Accuracy: 314/450 (69.78%), -1: 148.317 10201774.0\t0: 27.856 34445.8\t1: 8.521 1603.5\t\n",
      "Average loss: 0.0078, Accuracy: 276/450 (61.33%), -1: 148.831 10586083.0\t0: 27.937 43049.6\t1: 8.035 1497.9\t\n",
      "Average loss: 0.0099, Accuracy: 246/450 (54.67%), -1: 147.878 10159055.0\t0: 28.005 37294.9\t1: 4.956 979.5\t\n",
      "Average loss: 0.0072, Accuracy: 304/450 (67.56%), -1: 147.956 10038727.0\t0: 26.728 22718.6\t1: 3.346 120.9\t\n",
      "Average loss: 0.0049, Accuracy: 340/450 (75.56%), -1: 147.159 9741780.0\t0: 27.047 17681.5\t1: 4.442 35.4\t\n",
      "Average loss: 0.0034, Accuracy: 371/450 (82.44%), -1: 149.512 10820183.0\t0: 26.437 18715.0\t1: 6.714 373.2\t\n",
      "Average loss: 0.0021, Accuracy: 409/450 (90.89%), -1: 148.250 9993095.0\t0: 27.475 31392.8\t1: 7.173 856.3\t\n",
      "Training 4 epochs per shift, shifting window by 4 indices 16 times\n",
      "4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, \n",
      "Average loss: 0.0029, Accuracy: 378/450 (84.00%), -1: 148.897 10569195.0\t0: 26.803 25366.3\t1: 7.853 2842.9\t\n",
      "Average loss: 0.0038, Accuracy: 359/450 (79.78%), -1: 148.861 10549914.0\t0: 27.076 32900.3\t1: 5.769 322.4\t\n",
      "Average loss: 0.0051, Accuracy: 340/450 (75.56%), -1: 148.369 10287678.0\t0: 26.549 20277.4\t1: 4.143 43.3\t\n",
      "Average loss: 0.0047, Accuracy: 337/450 (74.89%), -1: 148.471 10422801.0\t0: 26.305 20491.3\t1: 5.624 140.6\t\n",
      "Average loss: 0.0062, Accuracy: 313/450 (69.56%), -1: 149.274 10954122.0\t0: 26.612 22302.7\t1: 7.917 2295.8\t\n",
      "Average loss: 0.0086, Accuracy: 271/450 (60.22%), -1: 149.115 10617467.0\t0: 26.459 17719.8\t1: 7.500 950.3\t\n",
      "Average loss: 0.0074, Accuracy: 293/450 (65.11%), -1: 148.263 10257504.0\t0: 27.676 27904.6\t1: 7.337 650.8\t\n",
      "Average loss: 0.0086, Accuracy: 276/450 (61.33%), -1: 147.550 9931651.0\t0: 26.827 21256.6\t1: 3.852 264.5\t\n",
      "Average loss: 0.0089, Accuracy: 270/450 (60.00%), -1: 148.498 10295501.0\t0: 26.950 30190.4\t1: 7.307 863.1\t\n",
      "Average loss: 0.0067, Accuracy: 298/450 (66.22%), -1: 148.281 10236619.0\t0: 26.489 23431.1\t1: 2.088 5.4\t\n",
      "Average loss: 0.0065, Accuracy: 297/450 (66.00%), -1: 148.910 10469845.0\t0: 26.670 29923.3\t1: 9.441 2182.1\t\n",
      "Average loss: 0.0057, Accuracy: 305/450 (67.78%), -1: 148.982 10564926.0\t0: 26.436 23405.6\t1: 4.078 28.6\t\n",
      "Average loss: 0.0038, Accuracy: 363/450 (80.67%), -1: 148.628 10514298.0\t0: 27.214 26837.5\t1: 6.682 688.2\t\n",
      "Average loss: 0.0027, Accuracy: 388/450 (86.22%), -1: 148.615 10518989.0\t0: 27.116 20550.8\t1: 5.971 288.8\t\n",
      "Average loss: 0.0028, Accuracy: 390/450 (86.67%), -1: 149.075 10647870.0\t0: 27.008 27054.5\t1: 8.710 2139.6\t\n",
      "Average loss: 0.0026, Accuracy: 390/450 (86.67%), -1: 148.247 10200486.0\t0: 26.871 26190.9\t1: 10.091 3033.6\t\n",
      "Average loss: 0.0028, Accuracy: 392/450 (87.11%), -1: 149.049 10509674.0\t0: 26.755 17829.0\t1: 4.433 44.1\t\n",
      "Training 2 epochs per shift, shifting window by 2 indices 32 times\n",
      "2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, \n",
      "Average loss: 0.0031, Accuracy: 378/450 (84.00%), -1: 148.638 10273349.0\t0: 27.272 27606.5\t1: 4.711 171.5\t\n",
      "Average loss: 0.0043, Accuracy: 335/450 (74.44%), -1: 149.121 10864202.0\t0: 26.361 21129.9\t1: 5.647 125.5\t\n",
      "Average loss: 0.0044, Accuracy: 349/450 (77.56%), -1: 148.605 10421646.0\t0: 26.827 17428.8\t1: 6.594 336.5\t\n",
      "Average loss: 0.0042, Accuracy: 355/450 (78.89%), -1: 149.586 10951076.0\t0: 26.784 23875.4\t1: 5.120 159.7\t\n",
      "Average loss: 0.0046, Accuracy: 351/450 (78.00%), -1: 148.795 10545872.0\t0: 26.676 18697.8\t1: 5.502 298.3\t\n",
      "Average loss: 0.0051, Accuracy: 322/450 (71.56%), -1: 147.980 10184895.0\t0: 27.525 26576.6\t1: 6.288 712.0\t\n",
      "Average loss: 0.0050, Accuracy: 323/450 (71.78%), -1: 147.887 9964581.0\t0: 27.012 26782.6\t1: 5.282 211.7\t\n",
      "Average loss: 0.0051, Accuracy: 329/450 (73.11%), -1: 147.858 10061015.0\t0: 26.726 23419.1\t1: 5.413 95.7\t\n",
      "Average loss: 0.0072, Accuracy: 291/450 (64.67%), -1: 147.675 10069428.0\t0: 26.684 23208.4\t1: 5.482 141.4\t\n",
      "Average loss: 0.0062, Accuracy: 315/450 (70.00%), -1: 148.415 10330956.0\t0: 27.095 24961.5\t1: 7.179 788.3\t\n",
      "Average loss: 0.0070, Accuracy: 291/450 (64.67%), -1: 147.523 9761923.0\t0: 26.210 15782.3\t1: 5.728 136.8\t\n",
      "Average loss: 0.0075, Accuracy: 284/450 (63.11%), -1: 148.376 10359294.0\t0: 26.069 22939.1\t1: 4.628 35.2\t\n",
      "Average loss: 0.0072, Accuracy: 287/450 (63.78%), -1: 148.391 10251656.0\t0: 27.419 32297.6\t1: 6.337 3246.0\t\n",
      "Average loss: 0.0077, Accuracy: 267/450 (59.33%), -1: 146.954 9538744.0\t0: 26.944 26322.0\t1: 5.972 203.1\t\n",
      "Average loss: 0.0082, Accuracy: 269/450 (59.78%), -1: 147.967 9896239.0\t0: 26.555 17488.0\t1: 5.529 468.0\t\n",
      "Average loss: 0.0090, Accuracy: 259/450 (57.56%), -1: 148.105 10169283.0\t0: 26.609 28063.3\t1: 9.007 2337.6\t\n",
      "Average loss: 0.0089, Accuracy: 254/450 (56.44%), -1: 149.569 10780350.0\t0: 26.873 24162.6\t1: 6.411 1164.9\t\n",
      "Average loss: 0.0069, Accuracy: 287/450 (63.78%), -1: 148.482 10477996.0\t0: 27.446 24768.0\t1: 2.390 14.7\t\n",
      "Average loss: 0.0065, Accuracy: 315/450 (70.00%), -1: 149.010 10689835.0\t0: 27.073 27361.4\t1: 6.836 922.1\t\n",
      "Average loss: 0.0062, Accuracy: 311/450 (69.11%), -1: 148.403 10408650.0\t0: 25.470 12751.8\t1: 4.825 51.5\t\n",
      "Average loss: 0.0060, Accuracy: 310/450 (68.89%), -1: 147.884 9837339.0\t0: 25.688 13810.8\t1: 6.865 1045.1\t\n",
      "Average loss: 0.0057, Accuracy: 319/450 (70.89%), -1: 147.452 9821170.0\t0: 26.713 23177.1\t1: 7.274 1597.3\t\n",
      "Average loss: 0.0065, Accuracy: 298/450 (66.22%), -1: 148.648 10468484.0\t0: 25.944 14863.6\t1: 4.612 34.4\t\n",
      "Average loss: 0.0048, Accuracy: 332/450 (73.78%), -1: 148.763 10501839.0\t0: 26.551 20107.7\t1: 4.217 53.8\t\n",
      "Average loss: 0.0041, Accuracy: 359/450 (79.78%), -1: 148.776 10465751.0\t0: 27.347 30017.4\t1: 7.838 2752.4\t\n",
      "Average loss: 0.0037, Accuracy: 361/450 (80.22%), -1: 148.869 10809005.0\t0: 27.178 27537.7\t1: 4.686 738.2\t\n",
      "Average loss: 0.0033, Accuracy: 368/450 (81.78%), -1: 148.759 10569720.0\t0: 27.234 25977.1\t1: 6.840 534.3\t\n",
      "Average loss: 0.0031, Accuracy: 376/450 (83.56%), -1: 147.874 10036959.0\t0: 26.312 21870.9\t1: 6.525 337.6\t\n",
      "Average loss: 0.0030, Accuracy: 378/450 (84.00%), -1: 149.444 10851551.0\t0: 26.793 18218.6\t1: 6.017 487.6\t\n",
      "Average loss: 0.0025, Accuracy: 406/450 (90.22%), -1: 148.628 10265561.0\t0: 26.214 15930.7\t1: 6.490 762.5\t\n",
      "Average loss: 0.0027, Accuracy: 391/450 (86.89%), -1: 148.261 10181544.0\t0: 26.697 21503.8\t1: 4.711 758.7\t\n",
      "Average loss: 0.0030, Accuracy: 371/450 (82.44%), -1: 148.220 10097563.0\t0: 26.437 21802.2\t1: 4.935 180.0\t\n",
      "Average loss: 0.0027, Accuracy: 395/450 (87.78%), -1: 148.620 10532633.0\t0: 26.949 22811.3\t1: 5.779 687.9\t\n",
      "Training 1 epochs per shift, shifting window by 1 indices 64 times\n",
      "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, \n",
      "Average loss: 0.0032, Accuracy: 372/450 (82.67%), -1: 147.705 9962418.0\t0: 26.336 20413.0\t1: 4.703 40.6\t\n",
      "Average loss: 0.0030, Accuracy: 379/450 (84.22%), -1: 148.876 10583382.0\t0: 27.394 38191.1\t1: 7.088 857.4\t\n",
      "Average loss: 0.0042, Accuracy: 344/450 (76.44%), -1: 148.156 9931825.0\t0: 26.908 21536.2\t1: 5.076 65.2\t\n",
      "Average loss: 0.0041, Accuracy: 348/450 (77.33%), -1: 147.946 10193586.0\t0: 27.081 21297.2\t1: 4.209 63.1\t\n",
      "Average loss: 0.0049, Accuracy: 330/450 (73.33%), -1: 149.143 10774263.0\t0: 27.343 24003.6\t1: 5.218 75.5\t\n",
      "Average loss: 0.0045, Accuracy: 338/450 (75.11%), -1: 148.412 10509709.0\t0: 26.911 24810.0\t1: 6.217 1083.7\t\n",
      "Average loss: 0.0046, Accuracy: 336/450 (74.67%), -1: 148.263 10325670.0\t0: 26.821 25196.2\t1: 7.911 863.5\t\n",
      "Average loss: 0.0049, Accuracy: 322/450 (71.56%), -1: 148.895 10419916.0\t0: 27.952 44226.9\t1: 8.778 2633.3\t\n",
      "Average loss: 0.0053, Accuracy: 323/450 (71.78%), -1: 147.583 9759038.0\t0: 27.411 29375.5\t1: 7.211 1418.8\t\n",
      "Average loss: 0.0046, Accuracy: 338/450 (75.11%), -1: 148.207 10362454.0\t0: 27.452 26118.6\t1: 6.975 1023.4\t\n",
      "Average loss: 0.0058, Accuracy: 308/450 (68.44%), -1: 147.744 10099003.0\t0: 26.676 25626.3\t1: 6.489 425.0\t\n",
      "Average loss: 0.0047, Accuracy: 347/450 (77.11%), -1: 148.632 10556740.0\t0: 26.170 16322.0\t1: 5.683 141.7\t\n",
      "Average loss: 0.0052, Accuracy: 323/450 (71.78%), -1: 148.265 10297093.0\t0: 26.680 22744.7\t1: 6.520 316.4\t\n",
      "Average loss: 0.0049, Accuracy: 330/450 (73.33%), -1: 148.613 10399264.0\t0: 26.351 20828.6\t1: 4.476 30.4\t\n",
      "Average loss: 0.0054, Accuracy: 321/450 (71.33%), -1: 149.579 10845147.0\t0: 27.512 34072.5\t1: 8.458 1300.0\t\n",
      "Average loss: 0.0073, Accuracy: 280/450 (62.22%), -1: 149.549 10902313.0\t0: 27.143 23957.2\t1: 4.417 545.1\t\n",
      "Average loss: 0.0071, Accuracy: 296/450 (65.78%), -1: 148.021 10200194.0\t0: 26.403 21356.4\t1: 5.557 114.1\t\n",
      "Average loss: 0.0063, Accuracy: 293/450 (65.11%), -1: 148.135 10063233.0\t0: 26.625 25743.0\t1: 7.807 1240.5\t\n",
      "Average loss: 0.0072, Accuracy: 284/450 (63.11%), -1: 148.456 10775323.0\t0: 27.005 19387.4\t1: 6.146 748.6\t\n",
      "Average loss: 0.0072, Accuracy: 277/450 (61.56%), -1: 148.587 10573765.0\t0: 26.697 19046.8\t1: 4.744 42.6\t\n",
      "Average loss: 0.0075, Accuracy: 278/450 (61.78%), -1: 148.301 10111084.0\t0: 27.635 34696.7\t1: 6.709 640.9\t\n",
      "Average loss: 0.0078, Accuracy: 272/450 (60.44%), -1: 149.118 10724777.0\t0: 27.376 29430.4\t1: 8.002 1012.3\t\n",
      "Average loss: 0.0073, Accuracy: 286/450 (63.56%), -1: 148.279 10239790.0\t0: 27.271 27219.0\t1: 7.652 1970.6\t\n",
      "Average loss: 0.0074, Accuracy: 298/450 (66.22%), -1: 148.677 10484631.0\t0: 26.756 24846.9\t1: 6.886 777.6\t\n",
      "Average loss: 0.0072, Accuracy: 287/450 (63.78%), -1: 148.343 10259820.0\t0: 27.421 29720.7\t1: 7.792 1218.4\t\n",
      "Average loss: 0.0076, Accuracy: 268/450 (59.56%), -1: 149.351 10793262.0\t0: 27.524 34485.3\t1: 4.685 36.6\t\n",
      "Average loss: 0.0084, Accuracy: 259/450 (57.56%), -1: 149.711 11066780.0\t0: 27.284 28098.9\t1: 7.924 885.3\t\n",
      "Average loss: 0.0074, Accuracy: 284/450 (63.11%), -1: 148.243 10447553.0\t0: 26.613 18357.8\t1: 7.029 521.0\t\n",
      "Average loss: 0.0075, Accuracy: 283/450 (62.89%), -1: 149.085 10708707.0\t0: 27.111 24966.5\t1: 10.398 4306.4\t\n",
      "Average loss: 0.0072, Accuracy: 285/450 (63.33%), -1: 148.260 10127704.0\t0: 28.230 35099.5\t1: 8.317 2158.3\t\n",
      "Average loss: 0.0084, Accuracy: 272/450 (60.44%), -1: 149.376 10663312.0\t0: 27.202 27396.7\t1: 6.111 234.5\t\n",
      "Average loss: 0.0088, Accuracy: 261/450 (58.00%), -1: 148.460 10701095.0\t0: 26.116 17142.0\t1: 6.603 359.5\t\n",
      "Average loss: 0.0088, Accuracy: 249/450 (55.33%), -1: 148.060 10237977.0\t0: 26.687 21610.1\t1: 5.077 1105.2\t\n",
      "Average loss: 0.0085, Accuracy: 263/450 (58.44%), -1: 148.371 10230497.0\t0: 26.668 20904.9\t1: 3.635 22.4\t\n",
      "Average loss: 0.0067, Accuracy: 290/450 (64.44%), -1: 148.859 10667542.0\t0: 27.628 31147.9\t1: 5.051 165.4\t\n",
      "Average loss: 0.0059, Accuracy: 309/450 (68.67%), -1: 148.413 10140774.0\t0: 26.435 19452.8\t1: 6.606 480.5\t\n",
      "Average loss: 0.0049, Accuracy: 329/450 (73.11%), -1: 149.536 10632347.0\t0: 26.776 20033.3\t1: 7.184 541.9\t\n",
      "Average loss: 0.0067, Accuracy: 297/450 (66.00%), -1: 148.818 10591191.0\t0: 27.544 30467.2\t1: 4.497 33.9\t\n",
      "Average loss: 0.0059, Accuracy: 315/450 (70.00%), -1: 148.413 10402006.0\t0: 27.328 29903.9\t1: 8.279 2288.1\t\n",
      "Average loss: 0.0058, Accuracy: 317/450 (70.44%), -1: 148.800 10453949.0\t0: 28.087 37466.6\t1: 9.733 5914.2\t\n",
      "Average loss: 0.0064, Accuracy: 299/450 (66.44%), -1: 147.585 10244544.0\t0: 26.781 25746.7\t1: 5.398 182.0\t\n",
      "Average loss: 0.0063, Accuracy: 305/450 (67.78%), -1: 147.810 10057511.0\t0: 26.776 21430.9\t1: 7.823 976.4\t\n",
      "Average loss: 0.0056, Accuracy: 323/450 (71.78%), -1: 147.850 10008698.0\t0: 27.194 26485.4\t1: 5.212 75.8\t\n",
      "Average loss: 0.0057, Accuracy: 316/450 (70.22%), -1: 148.368 10339850.0\t0: 27.168 35228.0\t1: 4.233 17.2\t\n",
      "Average loss: 0.0057, Accuracy: 319/450 (70.89%), -1: 149.335 10632737.0\t0: 26.934 22282.5\t1: 5.414 153.9\t\n",
      "Average loss: 0.0058, Accuracy: 314/450 (69.78%), -1: 149.827 10874072.0\t0: 27.201 25764.1\t1: 6.683 340.8\t\n",
      "Average loss: 0.0054, Accuracy: 318/450 (70.67%), -1: 148.872 10436786.0\t0: 27.409 24936.6\t1: 7.176 992.7\t\n",
      "Average loss: 0.0041, Accuracy: 343/450 (76.22%), -1: 147.840 10156631.0\t0: 27.426 26728.1\t1: 6.391 659.0\t\n",
      "Average loss: 0.0039, Accuracy: 364/450 (80.89%), -1: 148.417 10247409.0\t0: 27.402 26140.6\t1: 5.312 134.5\t\n",
      "Average loss: 0.0042, Accuracy: 347/450 (77.11%), -1: 148.472 10401491.0\t0: 27.368 28097.0\t1: 4.894 919.9\t\n",
      "Average loss: 0.0041, Accuracy: 341/450 (75.78%), -1: 147.939 10179350.0\t0: 26.014 15192.4\t1: 4.368 68.9\t\n",
      "Average loss: 0.0035, Accuracy: 363/450 (80.67%), -1: 148.607 10615027.0\t0: 26.942 20292.0\t1: 8.780 1558.6\t\n",
      "Average loss: 0.0030, Accuracy: 388/450 (86.22%), -1: 148.689 10623382.0\t0: 26.725 26062.1\t1: 6.750 364.5\t\n",
      "Average loss: 0.0029, Accuracy: 388/450 (86.22%), -1: 148.914 10722812.0\t0: 26.530 18400.7\t1: 5.966 175.4\t\n",
      "Average loss: 0.0030, Accuracy: 375/450 (83.33%), -1: 148.871 10635296.0\t0: 27.837 46160.6\t1: 9.536 3149.0\t\n",
      "Average loss: 0.0028, Accuracy: 380/450 (84.44%), -1: 149.786 11014394.0\t0: 27.448 29737.6\t1: 5.571 220.1\t\n",
      "Average loss: 0.0028, Accuracy: 383/450 (85.11%), -1: 147.962 10113607.0\t0: 26.688 18507.1\t1: 6.676 1294.9\t\n",
      "Average loss: 0.0027, Accuracy: 395/450 (87.78%), -1: 148.508 10410365.0\t0: 27.928 36100.0\t1: 4.660 717.9\t\n",
      "Average loss: 0.0028, Accuracy: 391/450 (86.89%), -1: 148.662 10350100.0\t0: 26.642 25583.6\t1: 4.175 406.4\t\n",
      "Average loss: 0.0027, Accuracy: 399/450 (88.67%), -1: 148.439 10561031.0\t0: 26.918 21344.7\t1: 5.343 198.6\t\n",
      "Average loss: 0.0027, Accuracy: 390/450 (86.67%), -1: 149.321 10821334.0\t0: 26.814 33327.5\t1: 9.091 1794.5\t\n",
      "Average loss: 0.0029, Accuracy: 384/450 (85.33%), -1: 149.156 10644860.0\t0: 25.781 15525.5\t1: 3.994 12.8\t\n",
      "Average loss: 0.0030, Accuracy: 384/450 (85.33%), -1: 149.476 10839750.0\t0: 27.242 23794.4\t1: 3.586 7.5\t\n",
      "Average loss: 0.0033, Accuracy: 369/450 (82.00%), -1: 147.574 9997676.0\t0: 25.828 14031.6\t1: 5.216 149.9\t\n",
      "Average loss: 0.0030, Accuracy: 383/450 (85.11%), -1: 148.313 10375946.0\t0: 27.626 47855.5\t1: 8.496 1814.2\t\n"
     ]
    }
   ],
   "source": [
    "for power in range(int(math.log(base_data.input_dim, 2))):\n",
    "    mod = copy.deepcopy(model)\n",
    "    mod_optimizer = torch.optim.SGD(mod.parameters(), lr=0.01)\n",
    "    mod_optimizer.load_state_dict(optimizer.state_dict())\n",
    "\n",
    "    shift = 2**(int(math.log(base_data.input_dim, 2))-power-1)\n",
    "    datasets = [val_loader]\n",
    "    print(\"Training {} epochs per shift, shifting window by {} indices {} times\".format(64//int(base_data.input_dim/shift), shift, int(base_data.input_dim/shift)))\n",
    "    for step in range(int(base_data.input_dim/shift)):\n",
    "        modded_data = copy.deepcopy(base_data)\n",
    "        modded_data.shift_window((step+1)*shift)\n",
    "        print(modded_data.window_index, end=\", \")\n",
    "        modded_train_loader, modded_val_loader, modded_test_loader = split_dataset(modded_data, val_size = 0.1, test_size = 0.1, batch_size = 128)\n",
    "        datasets.append(modded_val_loader)\n",
    "        train(mod, modded_train_loader, mod_optimizer, criterion, epochs=64//int(base_data.input_dim/shift), val_loader=modded_val_loader, device=device, regression=regression, verbose=False, val_verbose=False)\n",
    "    print()\n",
    "    for vl in datasets:\n",
    "        test(mod, vl, criterion, device=device, regression=regression, metrics=True)\n",
    "        print(\", \", end=\"\")\n",
    "        for key, value in mod.activations.items():\n",
    "            print(\"{}: {:.3f} {}\".format(key, effective_rank(value, partial=True).item(), round(orthogonality_gap(value).item(), 1)), end=\"\\t\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 147.673 10035187.0\t0: 27.996 61267.8\t1: 10.830 37350.9\t\n",
      "tensor([0.3890, 0.1954, 0.3459, 0.7973, 0.0509, 0.0724, 0.5273, 1.0188, 0.2346,\n",
      "        0.2770, 0.0758, 0.5836, 0.4636, 0.2153, 0.0439, 0.3187])\n",
      "Training 32 epochs per shift, shifting window by 32 indices 2 times\n",
      "\n",
      "Average loss: 0.0006, Accuracy: 441/450 (98.00%), -1: 148.120 10245874.0\t0: 27.025 29761.9\t1: 14.030 76687.7\t\n",
      "Training 16 epochs per shift, shifting window by 16 indices 4 times\n",
      "-1: 151.746 24108056.0\t0: 27.996 173721.8\t1: 11.771 53829.2\t\n",
      "tensor([0.4379, 0.2986, 0.1063, 0.9323, 0.0204, 0.0697, 0.6269, 0.0410, 0.1795,\n",
      "        0.0164, 0.1723, 0.8169, 0.0486, 0.0930, 0.0265, 0.4312])\n",
      "-1: 158.716 142573168.0\t0: 29.119 411521.7\t1: 9.506 11114.8\t\n",
      "tensor([3.7592e-01, 2.4798e-01, 2.3430e-01, 9.4914e-01, 3.1781e-03, 1.2304e-01,\n",
      "        9.7981e-01, 2.5686e-02, 3.5922e-01, 5.7804e-04, 2.0119e-01, 1.3373e+00,\n",
      "        3.6713e-02, 1.1464e-01, 1.2492e-02, 4.9028e-01])\n",
      "\n",
      "Average loss: 0.0044, Accuracy: 317/450 (70.44%), -1: 147.414 9821419.0\t0: 25.727 26963.8\t1: 5.270 421.7\t\n",
      "Average loss: 0.0027, Accuracy: 374/450 (83.11%), -1: 152.446 25047524.0\t0: 27.406 60922.5\t1: 9.980 3571.0\t\n",
      "Average loss: 0.0003, Accuracy: 444/450 (98.67%), -1: 160.292 151508128.0\t0: 27.351 644432.1\t1: 13.544 99041.5\t\n",
      "Training 8 epochs per shift, shifting window by 8 indices 8 times\n",
      "-1: 150.553 13007981.0\t0: 27.607 81651.8\t1: 13.124 24231.7\t\n",
      "tensor([0.3046, 0.1745, 0.1971, 0.8481, 0.0454, 0.1089, 0.7396, 0.2353, 0.3618,\n",
      "        0.0853, 0.1188, 0.8402, 0.1505, 0.1597, 0.0197, 0.3262])\n",
      "-1: 153.615 26915022.0\t0: 28.636 234932.4\t1: 10.592 33864.4\t\n",
      "tensor([0.3446, 0.3085, 0.2517, 1.3599, 0.0111, 0.1068, 0.9594, 0.0396, 0.3202,\n",
      "        0.0126, 0.0888, 0.8512, 0.0425, 0.2517, 0.0045, 0.3595])\n",
      "-1: 155.754 64022744.0\t0: 27.117 517284.8\t1: 9.936 25501.6\t\n",
      "tensor([5.7352e-01, 3.8358e-01, 2.7373e-01, 1.2833e+00, 5.2716e-03, 1.4891e-01,\n",
      "        8.0267e-01, 0.0000e+00, 3.1001e-01, 0.0000e+00, 1.5510e-01, 8.2811e-01,\n",
      "        1.4255e-02, 4.6917e-02, 3.6106e-04, 4.6582e-01])\n",
      "-1: 159.457 144176608.0\t0: 26.917 1364589.1\t1: 10.060 26949.1\t\n",
      "tensor([0.4947, 0.3736, 0.3315, 0.7838, 0.0021, 0.1480, 0.5309, 0.0000, 0.3350,\n",
      "        0.0000, 0.1100, 0.7258, 0.0000, 0.0098, 0.0000, 0.5366])\n",
      "-1: 161.130 279850240.0\t0: 28.377 2053505.2\t1: 9.557 21442.8\t\n",
      "tensor([5.7102e-01, 4.6608e-01, 5.2226e-01, 1.0643e+00, 2.1491e-04, 2.3657e-01,\n",
      "        1.1633e+00, 0.0000e+00, 3.7026e-01, 0.0000e+00, 2.7957e-01, 9.3443e-01,\n",
      "        0.0000e+00, 1.1140e-02, 0.0000e+00, 6.9652e-01])\n",
      "-1: 163.051 490635680.0\t0: 28.751 3365852.2\t1: 5.926 2354.7\t\n",
      "tensor([0.5498, 0.3955, 0.3788, 1.5015, 0.0000, 0.2140, 1.1142, 0.0000, 0.5409,\n",
      "        0.0000, 0.1729, 1.3026, 0.0000, 0.0045, 0.0000, 0.8325])\n",
      "\n",
      "Average loss: 0.1890, Accuracy: 265/450 (58.89%), -1: 148.116 10121098.0\t0: 26.709 37913.0\t1: 277.146 23260444672.0\t\n",
      "Average loss: 0.2139, Accuracy: 201/450 (44.67%), -1: 150.958 12967415.0\t0: 27.138 34801.5\t1: 105.562 478147360.0\t\n",
      "Average loss: 0.1418, Accuracy: 228/450 (50.67%), -1: 152.709 26481620.0\t0: 27.086 71257.3\t1: 44.354 10166615.0\t\n",
      "Average loss: 0.0512, Accuracy: 341/450 (75.78%), -1: 154.574 62561804.0\t0: 28.196 310859.1\t1: 11.604 6022.7\t\n",
      "Average loss: 0.0060, Accuracy: 436/450 (96.89%), -1: 157.786 137377728.0\t0: 28.563 584810.4\t1: 6.208 890.0\t\n",
      "Average loss: 0.0016, Accuracy: 443/450 (98.44%), -1: 162.073 275351936.0\t0: 29.231 1091398.0\t1: 5.928 2359.7\t\n",
      "Average loss: 0.0003, Accuracy: 450/450 (100.00%), -1: 163.855 520332352.0\t0: 29.080 3444159.0\t1: 9.667 22571.6\t\n",
      "Training 4 epochs per shift, shifting window by 4 indices 16 times\n",
      "-1: 148.773 10462088.0\t0: 27.400 33786.2\t1: 10.049 13440.8\t\n",
      "tensor([0.2582, 0.2756, 0.1563, 0.6283, 0.0697, 0.0832, 0.4186, 0.6681, 0.1759,\n",
      "        0.2112, 0.1513, 0.6389, 0.5728, 0.1556, 0.0577, 0.3036])\n",
      "-1: 150.207 12604597.0\t0: 28.702 74747.1\t1: 9.902 14179.7\t\n",
      "tensor([0.3492, 0.1475, 0.1717, 0.8800, 0.1253, 0.0949, 0.7934, 0.5352, 0.4091,\n",
      "        0.1976, 0.0779, 0.7716, 0.5013, 0.1713, 0.0856, 0.3941])\n",
      "-1: 152.150 17428348.0\t0: 28.246 107128.3\t1: 10.096 4947.3\t\n",
      "tensor([0.3433, 0.5664, 0.1555, 0.9548, 0.0225, 0.2236, 0.8443, 0.1182, 0.4195,\n",
      "        0.0213, 0.1402, 0.7485, 0.0771, 0.0864, 0.0244, 0.3296])\n",
      "-1: 152.588 25339160.0\t0: 28.434 345635.9\t1: 7.140 5684.0\t\n",
      "tensor([5.3974e-01, 3.8810e-01, 3.3544e-01, 1.2758e+00, 1.9525e-02, 1.3426e-01,\n",
      "        9.6259e-01, 1.8074e-02, 3.6814e-01, 1.4117e-03, 2.4459e-01, 8.1732e-01,\n",
      "        1.6532e-02, 6.3700e-02, 6.8308e-05, 5.9455e-01])\n",
      "-1: 154.292 43057984.0\t0: 27.024 533863.2\t1: 7.938 4929.4\t\n",
      "tensor([0.3296, 0.3005, 0.3681, 1.2207, 0.0370, 0.2326, 1.3386, 0.0961, 0.4804,\n",
      "        0.0306, 0.1539, 1.1426, 0.1059, 0.1013, 0.0053, 0.4655])\n",
      "-1: 155.429 60685924.0\t0: 25.853 850183.8\t1: 8.390 11932.6\t\n",
      "tensor([0.5252, 0.3149, 0.3259, 0.5642, 0.0000, 0.1929, 0.7628, 0.0000, 0.3978,\n",
      "        0.0000, 0.1986, 0.6997, 0.0000, 0.0580, 0.0000, 0.5181])\n",
      "-1: 156.894 97949672.0\t0: 26.327 1465192.8\t1: 7.010 5220.1\t\n",
      "tensor([5.9419e-01, 2.1998e-01, 2.4674e-01, 1.7033e+00, 0.0000e+00, 1.4471e-01,\n",
      "        1.3791e+00, 0.0000e+00, 5.8877e-01, 0.0000e+00, 1.8381e-01, 1.0684e+00,\n",
      "        0.0000e+00, 2.5783e-02, 2.7022e-05, 6.9910e-01])\n",
      "-1: 158.135 140198640.0\t0: 26.909 1506027.5\t1: 5.747 2030.6\t\n",
      "tensor([0.3630, 0.6348, 0.3323, 1.1990, 0.0000, 0.1824, 1.1389, 0.0000, 0.5376,\n",
      "        0.0000, 0.2384, 1.1919, 0.0000, 0.0539, 0.0000, 0.6805])\n",
      "-1: 158.739 198498208.0\t0: 26.952 1832009.9\t1: 7.820 8652.9\t\n",
      "tensor([0.6169, 0.3431, 0.3109, 1.1326, 0.0000, 0.3840, 1.1143, 0.0000, 0.2765,\n",
      "        0.0000, 0.2061, 0.5827, 0.0000, 0.0525, 0.0000, 0.6168])\n",
      "-1: 161.795 288575680.0\t0: 28.660 2439427.2\t1: 6.413 3435.0\t\n",
      "tensor([5.2814e-01, 3.4599e-01, 4.9372e-01, 7.7163e-01, 4.9956e-05, 3.3241e-01,\n",
      "        6.3796e-01, 0.0000e+00, 5.1310e-01, 0.0000e+00, 1.7666e-01, 8.6771e-01,\n",
      "        0.0000e+00, 2.8412e-02, 0.0000e+00, 7.3502e-01])\n",
      "-1: 163.283 370934912.0\t0: 28.039 2569359.8\t1: 7.978 9481.1\t\n",
      "tensor([0.5084, 0.3935, 0.3207, 0.9964, 0.0000, 0.1761, 1.1212, 0.0000, 0.4651,\n",
      "        0.0000, 0.2886, 0.6309, 0.0000, 0.0268, 0.0000, 0.4995])\n",
      "-1: 162.555 510801312.0\t0: 30.531 3657592.0\t1: 6.984 5128.0\t\n",
      "tensor([5.2235e-01, 6.2204e-01, 4.6347e-01, 1.2845e+00, 8.0301e-04, 1.9731e-01,\n",
      "        9.0499e-01, 0.0000e+00, 4.9124e-01, 0.0000e+00, 1.8770e-01, 1.1084e+00,\n",
      "        0.0000e+00, 3.1317e-02, 0.0000e+00, 9.5687e-01])\n",
      "-1: 166.175 662428160.0\t0: 29.598 2852060.5\t1: 7.577 7485.1\t\n",
      "tensor([0.4025, 0.3451, 0.4969, 1.6729, 0.0000, 0.2132, 1.2811, 0.0000, 0.4326,\n",
      "        0.0000, 0.3740, 1.3343, 0.0000, 0.0242, 0.0045, 0.9333])\n",
      "-1: 167.073 859654144.0\t0: 30.213 5116111.5\t1: 7.169 5794.2\t\n",
      "tensor([0.4430, 0.5262, 0.4056, 1.2157, 0.0000, 0.3066, 1.0905, 0.0000, 0.5207,\n",
      "        0.0000, 0.2658, 1.2843, 0.0000, 0.0172, 0.0000, 0.9084])\n",
      "\n",
      "Average loss: 1.9306, Accuracy: 245/450 (54.44%), -1: 147.772 10027251.0\t0: 25.873 98088.3\t1: 964.552 3447945691136.0\t\n",
      "Average loss: 2.4059, Accuracy: 168/450 (37.33%), -1: 148.733 10601844.0\t0: 26.593 72349.9\t1: 1110.669 6065042751488.0\t\n",
      "Average loss: 2.1445, Accuracy: 148/450 (32.89%), -1: 150.755 12421254.0\t0: 27.323 67775.4\t1: 1161.169 7246777942016.0\t\n",
      "Average loss: 2.1775, Accuracy: 132/450 (29.33%), -1: 151.012 16219765.0\t0: 27.771 53060.5\t1: 787.733 1532387655680.0\t\n",
      "Average loss: 1.7191, Accuracy: 141/450 (31.33%), -1: 152.651 25414640.0\t0: 27.941 74557.6\t1: 355.898 61016244224.0\t\n",
      "Average loss: 1.2324, Accuracy: 198/450 (44.00%), -1: 154.104 41696976.0\t0: 28.067 86822.0\t1: 667.560 789615214592.0\t\n",
      "Average loss: 0.6913, Accuracy: 257/450 (57.11%), -1: 155.732 60756216.0\t0: 28.326 117977.4\t1: 420.762 119757250560.0\t\n",
      "Average loss: 0.4334, Accuracy: 323/450 (71.78%), -1: 158.075 93591568.0\t0: 29.380 205939.1\t1: 180.352 4138925824.0\t\n",
      "Average loss: 0.1955, Accuracy: 379/450 (84.22%), -1: 157.521 130283544.0\t0: 29.220 275882.8\t1: 19.563 221504.4\t\n",
      "Average loss: 0.0804, Accuracy: 416/450 (92.44%), -1: 159.807 203602896.0\t0: 27.898 558219.3\t1: 4.888 913.7\t\n",
      "Average loss: 0.0254, Accuracy: 432/450 (96.00%), -1: 161.439 282322880.0\t0: 26.877 1500248.6\t1: 4.672 727.1\t\n",
      "Average loss: 0.0073, Accuracy: 444/450 (98.67%), -1: 163.359 372997120.0\t0: 28.697 1306923.1\t1: 6.112 2732.5\t\n",
      "Average loss: 0.0011, Accuracy: 447/450 (99.33%), -1: 163.759 511747328.0\t0: 26.377 1697270.5\t1: 7.538 7307.5\t\n",
      "Average loss: 0.0003, Accuracy: 450/450 (100.00%), -1: 165.948 661650816.0\t0: 28.613 2745218.8\t1: 8.259 11103.3\t\n",
      "Average loss: 0.0001, Accuracy: 450/450 (100.00%), -1: 167.073 843928512.0\t0: 29.261 4626930.0\t1: 6.639 4044.5\t\n",
      "Training 2 epochs per shift, shifting window by 2 indices 32 times\n",
      "-1: 148.720 10556197.0\t0: 26.844 29039.8\t1: 8.351 1283.9\t\n",
      "tensor([0.2090, 0.1848, 0.1330, 0.6174, 0.1321, 0.1369, 0.2510, 0.7210, 0.1779,\n",
      "        0.1613, 0.0265, 0.2922, 0.5117, 0.2955, 0.0318, 0.1485])\n",
      "-1: 149.037 10700995.0\t0: 27.066 40587.4\t1: 8.333 1185.4\t\n",
      "tensor([0.2558, 0.2927, 0.1008, 0.5611, 0.0477, 0.0910, 0.4749, 0.5847, 0.1521,\n",
      "        0.3285, 0.0831, 0.6544, 0.4746, 0.1939, 0.0283, 0.1069])\n",
      "-1: 149.012 11415200.0\t0: 27.270 83698.6\t1: 8.626 13526.1\t\n",
      "tensor([0.3346, 0.1934, 0.2565, 0.6305, 0.0235, 0.1638, 0.5829, 0.0665, 0.2363,\n",
      "        0.0584, 0.1728, 0.5276, 0.1497, 0.0775, 0.0301, 0.3636])\n",
      "-1: 148.715 11374598.0\t0: 27.858 68189.3\t1: 7.252 1164.4\t\n",
      "tensor([0.1744, 0.2056, 0.2442, 0.8235, 0.1141, 0.2064, 0.7529, 0.6110, 0.3336,\n",
      "        0.0932, 0.0786, 0.4522, 0.1097, 0.1941, 0.0227, 0.3326])\n",
      "-1: 150.418 14040647.0\t0: 28.883 157566.0\t1: 9.415 3533.5\t\n",
      "tensor([0.4850, 0.1723, 0.3422, 1.6702, 0.0840, 0.1565, 1.0048, 0.3600, 0.2237,\n",
      "        0.1850, 0.0979, 1.0434, 0.2875, 0.2707, 0.0059, 0.5730])\n",
      "-1: 151.486 17953018.0\t0: 28.177 127047.2\t1: 8.248 1117.6\t\n",
      "tensor([0.4003, 0.2804, 0.1214, 0.9743, 0.1104, 0.2567, 0.7685, 0.4237, 0.4575,\n",
      "        0.1169, 0.1438, 0.9162, 0.3299, 0.1631, 0.0288, 0.3286])\n",
      "-1: 151.551 19596600.0\t0: 28.574 167727.8\t1: 6.191 2905.1\t\n",
      "tensor([0.3812, 0.1694, 0.1735, 1.1296, 0.0370, 0.0943, 0.8269, 0.1281, 0.2072,\n",
      "        0.0199, 0.1509, 1.2169, 0.2158, 0.1035, 0.0477, 0.3301])\n",
      "-1: 152.311 27309690.0\t0: 25.049 227975.5\t1: 7.014 5233.4\t\n",
      "tensor([0.3358, 0.2313, 0.2186, 0.7588, 0.0076, 0.1331, 0.5229, 0.0000, 0.3905,\n",
      "        0.0000, 0.1005, 0.9398, 0.0000, 0.0809, 0.0032, 0.6632])\n",
      "-1: 153.243 32354664.0\t0: 28.046 236172.7\t1: 6.107 2720.9\t\n",
      "tensor([3.4284e-01, 2.5795e-01, 2.4523e-01, 9.6449e-01, 1.6685e-02, 1.2076e-01,\n",
      "        9.1743e-01, 1.8513e-02, 2.9825e-01, 5.4826e-03, 1.2390e-01, 8.0821e-01,\n",
      "        7.8369e-03, 6.1543e-02, 8.4234e-05, 4.0248e-01])\n",
      "-1: 154.388 45198900.0\t0: 26.459 341022.2\t1: 7.595 7565.5\t\n",
      "tensor([3.3987e-01, 2.7383e-01, 1.8832e-01, 7.0952e-01, 8.3341e-03, 1.1620e-01,\n",
      "        4.8677e-01, 0.0000e+00, 5.3087e-01, 0.0000e+00, 7.9116e-02, 5.8959e-01,\n",
      "        2.2813e-03, 1.3878e-01, 5.2053e-04, 3.3610e-01])\n",
      "-1: 154.287 51073760.0\t0: 25.536 561928.9\t1: 4.466 577.0\t\n",
      "tensor([5.1484e-01, 2.4570e-01, 2.4609e-01, 1.3123e+00, 4.1376e-04, 1.5145e-01,\n",
      "        1.1818e+00, 2.4091e-02, 2.9631e-01, 1.5600e-02, 1.3242e-01, 1.2351e+00,\n",
      "        2.1579e-02, 5.2583e-02, 2.1759e-03, 5.6785e-01])\n",
      "-1: 155.042 66244596.0\t0: 25.578 618528.7\t1: 8.902 15591.7\t\n",
      "tensor([4.4298e-01, 1.9277e-01, 2.8704e-01, 1.2192e+00, 2.5954e-04, 1.2910e-01,\n",
      "        9.7124e-01, 0.0000e+00, 4.3629e-01, 0.0000e+00, 2.0561e-01, 9.1975e-01,\n",
      "        0.0000e+00, 5.3882e-02, 0.0000e+00, 4.1144e-01])\n",
      "-1: 155.873 74351008.0\t0: 26.732 564308.8\t1: 6.887 4805.4\t\n",
      "tensor([0.4877, 0.3804, 0.2484, 1.2176, 0.0277, 0.1909, 1.0518, 0.0052, 0.3572,\n",
      "        0.0063, 0.1325, 1.2033, 0.0000, 0.0647, 0.0000, 0.4824])\n",
      "-1: 156.770 95289608.0\t0: 26.486 758138.2\t1: 6.236 3005.2\t\n",
      "tensor([5.3793e-01, 3.8622e-01, 1.8334e-01, 1.1773e+00, 7.7161e-04, 2.5973e-01,\n",
      "        1.2088e+00, 0.0000e+00, 5.4916e-01, 0.0000e+00, 1.9558e-01, 7.7705e-01,\n",
      "        0.0000e+00, 5.9824e-02, 0.0000e+00, 4.5430e-01])\n",
      "-1: 157.748 114584024.0\t0: 25.846 675262.9\t1: 6.674 4146.1\t\n",
      "tensor([5.6282e-01, 4.0711e-01, 3.1354e-01, 1.1627e+00, 3.6687e-04, 7.7674e-02,\n",
      "        6.5268e-01, 0.0000e+00, 5.4728e-01, 0.0000e+00, 1.5980e-01, 9.5048e-01,\n",
      "        6.7620e-05, 7.8843e-02, 7.7380e-06, 4.0053e-01])\n",
      "-1: 158.823 130634960.0\t0: 27.243 1203225.8\t1: 6.807 4548.4\t\n",
      "tensor([3.2973e-01, 3.0779e-01, 3.2985e-01, 1.1697e+00, 9.3456e-05, 1.1491e-01,\n",
      "        5.7909e-01, 0.0000e+00, 4.4241e-01, 0.0000e+00, 1.3241e-01, 7.6342e-01,\n",
      "        0.0000e+00, 5.6421e-02, 8.0205e-06, 5.5301e-01])\n",
      "-1: 159.551 163868672.0\t0: 26.800 1145124.8\t1: 6.333 3235.5\t\n",
      "tensor([0.5114, 0.2396, 0.1793, 1.3307, 0.0048, 0.1777, 1.0328, 0.0000, 0.3444,\n",
      "        0.0000, 0.2270, 1.2148, 0.0000, 0.0788, 0.0000, 0.6416])\n",
      "-1: 159.625 199481680.0\t0: 25.777 1091881.6\t1: 8.531 12869.6\t\n",
      "tensor([5.5139e-01, 2.9617e-01, 3.3846e-01, 1.5998e+00, 0.0000e+00, 1.1388e-01,\n",
      "        9.4013e-01, 0.0000e+00, 4.0021e-01, 0.0000e+00, 9.6306e-02, 9.4598e-01,\n",
      "        0.0000e+00, 5.1228e-02, 5.9430e-05, 5.2172e-01])\n",
      "-1: 160.576 234623584.0\t0: 26.037 1446985.2\t1: 8.082 10059.2\t\n",
      "tensor([0.3716, 0.1972, 0.2953, 0.6706, 0.0000, 0.1732, 0.7803, 0.0000, 0.5173,\n",
      "        0.0000, 0.1659, 1.1880, 0.0000, 0.0340, 0.0000, 0.4554])\n",
      "-1: 161.207 277620544.0\t0: 26.370 1331844.6\t1: 7.879 8955.7\t\n",
      "tensor([0.5710, 0.4848, 0.2991, 0.9969, 0.0000, 0.1416, 1.1007, 0.0000, 0.4323,\n",
      "        0.0000, 0.1420, 0.5675, 0.0000, 0.0214, 0.0000, 0.9008])\n",
      "-1: 162.635 324522816.0\t0: 26.124 1082720.2\t1: 8.634 13583.2\t\n",
      "tensor([0.5366, 0.2364, 0.3182, 1.2105, 0.0000, 0.1480, 1.2210, 0.0000, 0.6659,\n",
      "        0.0000, 0.2155, 1.1554, 0.0000, 0.0179, 0.0000, 0.3351])\n",
      "-1: 162.268 380914080.0\t0: 26.226 1334946.6\t1: 8.755 14469.1\t\n",
      "tensor([0.4173, 0.4166, 0.1942, 0.9606, 0.0000, 0.0762, 0.7978, 0.0000, 0.4568,\n",
      "        0.0000, 0.2435, 0.7576, 0.0000, 0.0997, 0.0000, 0.4659])\n",
      "-1: 162.712 417359520.0\t0: 25.969 1266708.6\t1: 8.767 14554.9\t\n",
      "tensor([0.3059, 0.4702, 0.3330, 1.3222, 0.0000, 0.1048, 1.0117, 0.0000, 0.3548,\n",
      "        0.0000, 0.1362, 0.8261, 0.0000, 0.0862, 0.0000, 0.4102])\n",
      "-1: 163.140 475701472.0\t0: 27.020 1680897.9\t1: 8.531 12869.5\t\n",
      "tensor([0.2917, 0.2990, 0.3263, 1.1225, 0.0000, 0.1795, 1.1131, 0.0000, 0.3788,\n",
      "        0.0000, 0.1831, 0.6151, 0.0000, 0.0453, 0.0000, 0.5278])\n",
      "-1: 164.968 565175168.0\t0: 27.414 1410514.5\t1: 8.756 14476.4\t\n",
      "tensor([4.6474e-01, 4.7656e-01, 1.6665e-01, 1.4529e+00, 1.0541e-03, 2.8301e-01,\n",
      "        1.1268e+00, 0.0000e+00, 2.9623e-01, 0.0000e+00, 1.0229e-01, 9.5671e-01,\n",
      "        0.0000e+00, 4.1310e-02, 2.1973e-03, 6.9133e-01])\n",
      "-1: 165.225 621486848.0\t0: 26.392 1514549.6\t1: 6.960 5045.9\t\n",
      "tensor([0.6037, 0.3037, 0.1466, 1.1853, 0.0000, 0.2306, 0.7471, 0.0000, 0.3881,\n",
      "        0.0000, 0.2950, 1.1085, 0.0000, 0.0189, 0.0000, 0.5961])\n",
      "-1: 167.189 730631552.0\t0: 26.200 1410823.9\t1: 8.857 15244.4\t\n",
      "tensor([0.2497, 0.4333, 0.2192, 0.7136, 0.0000, 0.1403, 0.7300, 0.0000, 0.4602,\n",
      "        0.0000, 0.2437, 0.6039, 0.0000, 0.0340, 0.0000, 0.6992])\n",
      "-1: 167.791 849247424.0\t0: 27.156 1594932.1\t1: 8.606 13384.7\t\n",
      "tensor([0.4829, 0.4501, 0.3445, 0.7543, 0.0000, 0.1779, 0.7412, 0.0000, 0.3154,\n",
      "        0.0000, 0.1310, 0.7934, 0.0000, 0.0191, 0.0000, 0.5883])\n",
      "-1: 168.764 941860736.0\t0: 27.381 1706319.5\t1: 8.838 15093.0\t\n",
      "tensor([0.4505, 0.3765, 0.3633, 1.1835, 0.0000, 0.1843, 1.0553, 0.0000, 0.2758,\n",
      "        0.0000, 0.1225, 1.0602, 0.0000, 0.0889, 0.0000, 1.0318])\n",
      "-1: 167.627 1075640576.0\t0: 27.752 1909430.1\t1: 9.912 25234.1\t\n",
      "tensor([0.5680, 0.4192, 0.3734, 1.4116, 0.0000, 0.1737, 1.3996, 0.0000, 0.3024,\n",
      "        0.0000, 0.2281, 1.5756, 0.0000, 0.0460, 0.0000, 0.6125])\n",
      "\n",
      "Average loss: 1.0028, Accuracy: 245/450 (54.44%), -1: 147.060 9588081.0\t0: 25.723 137801.8\t1: 839.603 1978272579584.0\t\n",
      "Average loss: 1.0174, Accuracy: 206/450 (45.78%), -1: 150.123 11071755.0\t0: 26.201 106113.0\t1: 886.038 2454182952960.0\t\n",
      "Average loss: 1.3428, Accuracy: 172/450 (38.22%), -1: 148.414 10449055.0\t0: 24.451 75001.8\t1: 1170.146 7473690836992.0\t\n",
      "Average loss: 1.3816, Accuracy: 142/450 (31.56%), -1: 149.232 11246221.0\t0: 26.850 55223.4\t1: 601.789 521133850624.0\t\n",
      "Average loss: 1.2545, Accuracy: 146/450 (32.44%), -1: 150.023 12290845.0\t0: 26.627 55509.0\t1: 890.275 2501522227200.0\t\n",
      "Average loss: 1.2342, Accuracy: 137/450 (30.44%), -1: 150.883 14320455.0\t0: 27.166 53388.6\t1: 925.719 2924814794752.0\t\n",
      "Average loss: 1.3338, Accuracy: 119/450 (26.44%), -1: 150.563 16624076.0\t0: 26.557 45750.6\t1: 816.030 1765034426368.0\t\n",
      "Average loss: 1.2979, Accuracy: 115/450 (25.56%), -1: 152.754 21210914.0\t0: 25.963 36646.4\t1: 977.008 3629729185792.0\t\n",
      "Average loss: 1.0561, Accuracy: 131/450 (29.11%), -1: 152.435 26189622.0\t0: 26.121 26922.7\t1: 329.595 46633922560.0\t\n",
      "Average loss: 1.0029, Accuracy: 153/450 (34.00%), -1: 153.684 34533160.0\t0: 26.463 32700.2\t1: 488.031 225053835264.0\t\n",
      "Average loss: 0.7313, Accuracy: 196/450 (43.56%), -1: 154.037 40626372.0\t0: 26.491 38043.0\t1: 85.109 200182096.0\t\n",
      "Average loss: 0.5439, Accuracy: 215/450 (47.78%), -1: 153.866 51892568.0\t0: 27.204 68642.5\t1: 44.415 10396019.0\t\n",
      "Average loss: 0.5580, Accuracy: 232/450 (51.56%), -1: 155.045 61604588.0\t0: 26.977 64525.4\t1: 311.401 37132587008.0\t\n",
      "Average loss: 0.4719, Accuracy: 257/450 (57.11%), -1: 155.398 71200096.0\t0: 26.514 45929.4\t1: 3.480 151.1\t\n",
      "Average loss: 0.3689, Accuracy: 284/450 (63.11%), -1: 156.621 95568280.0\t0: 27.139 59430.7\t1: 92.857 253520208.0\t\n",
      "Average loss: 0.3033, Accuracy: 312/450 (69.33%), -1: 157.336 114968560.0\t0: 27.866 88013.3\t1: 98.663 363902464.0\t\n",
      "Average loss: 0.1774, Accuracy: 342/450 (76.00%), -1: 158.783 138538000.0\t0: 28.403 138385.7\t1: 52.639 22536454.0\t\n",
      "Average loss: 0.1600, Accuracy: 376/450 (83.56%), -1: 158.239 155009696.0\t0: 28.102 111797.4\t1: 31.924 2560539.0\t\n",
      "Average loss: 0.1055, Accuracy: 395/450 (87.78%), -1: 158.577 193897152.0\t0: 27.506 113194.5\t1: 26.462 1419822.0\t\n",
      "Average loss: 0.0325, Accuracy: 412/450 (91.56%), -1: 160.881 235065840.0\t0: 26.432 277664.7\t1: 4.948 971.7\t\n",
      "Average loss: 0.0354, Accuracy: 422/450 (93.78%), -1: 162.716 285688448.0\t0: 27.222 332242.2\t1: 6.196 2915.0\t\n",
      "Average loss: 0.0236, Accuracy: 425/450 (94.44%), -1: 161.988 334255904.0\t0: 26.271 293736.4\t1: 6.185 2891.2\t\n",
      "Average loss: 0.0088, Accuracy: 438/450 (97.33%), -1: 162.271 371177184.0\t0: 27.081 359529.6\t1: 24.624 463968.1\t\n",
      "Average loss: 0.0181, Accuracy: 439/450 (97.56%), -1: 163.561 423978688.0\t0: 28.341 453361.3\t1: 6.328 3222.8\t\n",
      "Average loss: 0.0020, Accuracy: 446/450 (99.11%), -1: 163.467 503806272.0\t0: 24.616 490673.5\t1: 4.478 585.3\t\n",
      "Average loss: 0.0022, Accuracy: 447/450 (99.33%), -1: 165.595 560500608.0\t0: 26.162 586834.5\t1: 7.334 6437.1\t\n",
      "Average loss: 0.0014, Accuracy: 447/450 (99.33%), -1: 165.547 634255040.0\t0: 26.631 769518.2\t1: 8.361 11745.5\t\n",
      "Average loss: 0.0005, Accuracy: 448/450 (99.56%), -1: 166.932 727665152.0\t0: 27.001 1076726.5\t1: 6.150 2812.6\t\n",
      "Average loss: 0.0002, Accuracy: 450/450 (100.00%), -1: 166.333 856406528.0\t0: 25.869 957382.6\t1: 7.176 5819.9\t\n",
      "Average loss: 0.0002, Accuracy: 450/450 (100.00%), -1: 167.495 928062336.0\t0: 25.327 978153.5\t1: 7.567 7439.1\t\n",
      "Average loss: 0.0001, Accuracy: 450/450 (100.00%), -1: 168.679 1020163648.0\t0: 26.508 1109397.0\t1: 7.505 7161.6\t\n",
      "Training 1 epochs per shift, shifting window by 1 indices 64 times\n",
      "-1: 147.996 10339860.0\t0: 27.235 35993.3\t1: 8.756 1479.7\t\n",
      "tensor([0.2417, 0.1089, 0.2491, 0.6795, 0.1180, 0.0534, 0.3963, 0.7621, 0.2194,\n",
      "        0.1777, 0.0629, 0.4075, 0.4939, 0.2712, 0.0257, 0.2785])\n",
      "-1: 147.487 10091212.0\t0: 26.911 27810.1\t1: 10.054 2976.0\t\n",
      "tensor([0.1540, 0.1717, 0.1526, 0.4424, 0.1800, 0.1627, 0.4318, 0.4612, 0.1940,\n",
      "        0.1492, 0.0587, 0.4048, 0.5609, 0.1386, 0.0656, 0.2804])\n",
      "-1: 148.589 10503361.0\t0: 26.404 22854.8\t1: 9.435 2247.9\t\n",
      "tensor([0.1995, 0.1315, 0.1414, 0.4277, 0.0922, 0.0456, 0.4517, 0.6673, 0.2488,\n",
      "        0.1804, 0.0499, 0.2439, 0.3083, 0.2558, 0.0091, 0.2261])\n",
      "-1: 149.114 10762818.0\t0: 27.017 24839.2\t1: 6.992 1600.5\t\n",
      "tensor([0.1545, 0.1686, 0.1706, 0.3668, 0.1234, 0.1304, 0.3706, 0.7229, 0.1732,\n",
      "        0.1576, 0.0461, 0.3988, 0.4541, 0.2197, 0.0852, 0.1432])\n",
      "-1: 148.355 10538605.0\t0: 27.681 45082.2\t1: 10.713 35599.7\t\n",
      "tensor([0.3009, 0.1421, 0.2552, 0.7089, 0.1104, 0.1493, 0.4091, 0.5863, 0.3091,\n",
      "        0.1475, 0.1311, 0.6504, 0.4555, 0.1447, 0.0342, 0.4311])\n",
      "-1: 149.558 11192825.0\t0: 27.152 31983.0\t1: 8.198 1096.9\t\n",
      "tensor([0.3345, 0.3076, 0.0953, 0.5996, 0.1005, 0.1363, 0.3802, 0.5351, 0.1864,\n",
      "        0.1129, 0.1147, 0.2751, 0.3629, 0.2469, 0.0315, 0.1263])\n",
      "-1: 150.448 12044699.0\t0: 27.305 41845.0\t1: 10.503 12064.6\t\n",
      "tensor([0.2659, 0.1430, 0.1824, 0.7683, 0.1158, 0.0692, 0.4133, 0.8723, 0.1594,\n",
      "        0.2830, 0.0899, 0.5416, 0.4734, 0.2152, 0.1168, 0.1783])\n",
      "-1: 150.846 12499883.0\t0: 26.745 24525.3\t1: 6.993 443.5\t\n",
      "tensor([0.2517, 0.2189, 0.1528, 0.4597, 0.1098, 0.1346, 0.3028, 0.3077, 0.2170,\n",
      "        0.0735, 0.1505, 0.3645, 0.3485, 0.1495, 0.0284, 0.2658])\n",
      "-1: 150.175 13724971.0\t0: 26.104 23405.6\t1: 6.337 326.2\t\n",
      "tensor([0.2713, 0.1521, 0.1721, 0.5089, 0.1300, 0.0745, 0.4344, 0.2353, 0.2487,\n",
      "        0.0792, 0.0677, 0.4080, 0.1773, 0.1050, 0.0292, 0.1100])\n",
      "-1: 151.435 14571336.0\t0: 26.659 26343.7\t1: 11.602 6412.1\t\n",
      "tensor([0.1964, 0.0961, 0.1310, 0.7386, 0.0971, 0.0774, 0.4305, 0.4925, 0.1745,\n",
      "        0.2351, 0.0503, 0.3941, 0.5178, 0.1282, 0.0469, 0.2604])\n",
      "-1: 152.122 15994239.0\t0: 27.665 57894.7\t1: 6.174 2861.6\t\n",
      "tensor([0.3345, 0.1990, 0.1546, 0.7220, 0.0989, 0.1566, 0.6701, 0.4202, 0.2463,\n",
      "        0.1502, 0.0970, 0.6036, 0.3821, 0.1235, 0.0382, 0.2501])\n",
      "-1: 152.009 18625036.0\t0: 27.185 53610.0\t1: 6.654 4087.3\t\n",
      "tensor([0.3111, 0.0770, 0.1160, 0.8108, 0.0438, 0.1062, 0.3442, 0.4133, 0.2534,\n",
      "        0.1301, 0.1060, 0.6891, 0.5788, 0.1449, 0.0103, 0.2083])\n",
      "-1: 151.437 19976524.0\t0: 26.611 27785.2\t1: 7.755 1376.9\t\n",
      "tensor([0.1898, 0.1425, 0.2071, 0.5293, 0.0791, 0.0811, 0.5065, 0.2795, 0.2421,\n",
      "        0.0872, 0.0471, 0.5226, 0.2954, 0.3545, 0.0117, 0.0997])\n",
      "-1: 151.562 20555906.0\t0: 27.060 39973.2\t1: 9.311 2182.8\t\n",
      "tensor([0.2682, 0.1286, 0.1206, 0.7628, 0.0486, 0.1197, 0.4716, 0.3326, 0.2045,\n",
      "        0.0747, 0.1239, 0.3635, 0.1943, 0.1273, 0.0483, 0.5397])\n",
      "-1: 151.797 23187862.0\t0: 26.084 49971.9\t1: 7.294 6277.1\t\n",
      "tensor([0.2441, 0.2314, 0.1026, 0.4909, 0.0266, 0.0833, 0.4272, 0.0484, 0.1771,\n",
      "        0.0008, 0.0572, 0.4031, 0.0725, 0.1622, 0.0083, 0.4469])\n",
      "-1: 151.957 25761374.0\t0: 26.826 44665.0\t1: 8.694 1419.5\t\n",
      "tensor([0.2647, 0.1788, 0.2316, 0.5699, 0.0449, 0.1547, 0.2753, 0.2136, 0.1745,\n",
      "        0.0293, 0.0916, 0.8484, 0.0885, 0.1989, 0.0249, 0.3631])\n",
      "-1: 153.459 29713684.0\t0: 27.028 26082.9\t1: 7.128 951.2\t\n",
      "tensor([0.2433, 0.1997, 0.1936, 0.7118, 0.0899, 0.0955, 0.4451, 0.2435, 0.2064,\n",
      "        0.1106, 0.0369, 0.4498, 0.3940, 0.2643, 0.0462, 0.1460])\n",
      "-1: 153.204 31970596.0\t0: 27.744 38592.9\t1: 9.255 2933.4\t\n",
      "tensor([0.3049, 0.1104, 0.1040, 0.6153, 0.1057, 0.0377, 0.6650, 0.4527, 0.1936,\n",
      "        0.1752, 0.0988, 0.5334, 0.5412, 0.3372, 0.0849, 0.3104])\n",
      "-1: 154.565 39936140.0\t0: 27.349 56815.7\t1: 4.449 565.7\t\n",
      "tensor([0.2891, 0.1039, 0.2330, 0.7990, 0.2223, 0.1365, 0.9624, 0.1469, 0.1949,\n",
      "        0.0741, 0.0227, 0.7746, 0.1697, 0.1244, 0.0172, 0.2601])\n",
      "-1: 153.321 39445400.0\t0: 27.157 35921.6\t1: 11.102 4907.3\t\n",
      "tensor([0.2046, 0.1752, 0.0863, 0.7406, 0.0567, 0.0910, 0.4395, 0.5841, 0.2036,\n",
      "        0.1161, 0.0798, 0.4680, 0.3024, 0.2523, 0.0424, 0.2414])\n",
      "-1: 154.165 46537572.0\t0: 27.714 65170.1\t1: 10.050 26831.6\t\n",
      "tensor([0.2271, 0.1253, 0.2363, 0.9469, 0.1014, 0.0611, 0.6018, 0.2129, 0.1607,\n",
      "        0.0460, 0.0775, 0.7041, 0.4242, 0.1024, 0.0811, 0.3594])\n",
      "-1: 154.614 52272596.0\t0: 27.774 47055.6\t1: 4.467 577.6\t\n",
      "tensor([0.2087, 0.2018, 0.1599, 0.7152, 0.2136, 0.0765, 0.8061, 0.3398, 0.2733,\n",
      "        0.1219, 0.0885, 0.6316, 0.3729, 0.1401, 0.0318, 0.2618])\n",
      "-1: 154.807 59378092.0\t0: 26.389 36925.9\t1: 5.073 1101.0\t\n",
      "tensor([0.2666, 0.1330, 0.1483, 0.4787, 0.0577, 0.1403, 0.5519, 0.0706, 0.5397,\n",
      "        0.0488, 0.0431, 0.5190, 0.0721, 0.1980, 0.0173, 0.2282])\n",
      "-1: 156.279 65754064.0\t0: 27.564 34932.5\t1: 5.508 1652.0\t\n",
      "tensor([0.2294, 0.1245, 0.0714, 0.6730, 0.1522, 0.1653, 0.5556, 0.3854, 0.1936,\n",
      "        0.0730, 0.0932, 0.7742, 0.3831, 0.2549, 0.0258, 0.2131])\n",
      "-1: 154.762 69938008.0\t0: 27.064 38529.8\t1: 9.588 21756.3\t\n",
      "tensor([0.2526, 0.1677, 0.1402, 0.5082, 0.0327, 0.1047, 0.3897, 0.4524, 0.1764,\n",
      "        0.1076, 0.0918, 0.5117, 0.4037, 0.3122, 0.0812, 0.2423])\n",
      "-1: 157.129 78876768.0\t0: 26.186 31927.2\t1: 8.547 12976.5\t\n",
      "tensor([0.1820, 0.1655, 0.0809, 0.3877, 0.0579, 0.0418, 0.5246, 0.0860, 0.2815,\n",
      "        0.0085, 0.1402, 0.6436, 0.0946, 0.2054, 0.0121, 0.2426])\n",
      "-1: 157.082 89145136.0\t0: 26.385 40625.2\t1: 7.959 9379.2\t\n",
      "tensor([0.2420, 0.2024, 0.0811, 0.6710, 0.0145, 0.0800, 0.5332, 0.1278, 0.1696,\n",
      "        0.0307, 0.0828, 0.5764, 0.2167, 0.1230, 0.0163, 0.3239])\n",
      "-1: 156.376 89581824.0\t0: 26.371 42864.4\t1: 5.549 1711.9\t\n",
      "tensor([0.1931, 0.1238, 0.1565, 0.4668, 0.0409, 0.0875, 0.6068, 0.1483, 0.3175,\n",
      "        0.0232, 0.0573, 0.4443, 0.1450, 0.1244, 0.0308, 0.2668])\n",
      "-1: 156.900 108879784.0\t0: 24.792 31036.7\t1: 5.648 1866.4\t\n",
      "tensor([1.8797e-01, 1.5875e-01, 2.1194e-01, 6.6036e-01, 3.2502e-02, 1.7026e-01,\n",
      "        4.6121e-01, 9.8986e-03, 2.0078e-01, 8.9295e-05, 6.6744e-02, 3.1639e-01,\n",
      "        2.2869e-01, 1.4144e-01, 1.8021e-02, 1.6854e-01])\n",
      "-1: 158.646 124347744.0\t0: 26.201 38257.1\t1: 6.934 2005.8\t\n",
      "tensor([0.1414, 0.0932, 0.0995, 0.7477, 0.0896, 0.0706, 0.4970, 0.0702, 0.3715,\n",
      "        0.0008, 0.0891, 0.5395, 0.0221, 0.2994, 0.0028, 0.1012])\n",
      "-1: 157.674 132530224.0\t0: 27.238 49259.7\t1: 8.926 8366.5\t\n",
      "tensor([0.2928, 0.1164, 0.0840, 0.9123, 0.0375, 0.1182, 0.6216, 0.2990, 0.2336,\n",
      "        0.0472, 0.0634, 0.4109, 0.1206, 0.3079, 0.0389, 0.2910])\n",
      "-1: 158.198 140127648.0\t0: 25.208 39233.9\t1: 7.554 3519.8\t\n",
      "tensor([0.0551, 0.1401, 0.1115, 0.6628, 0.0202, 0.1485, 0.5623, 0.0262, 0.2670,\n",
      "        0.0017, 0.1581, 0.4596, 0.1901, 0.1300, 0.0040, 0.2678])\n",
      "-1: 157.736 147050544.0\t0: 25.560 20364.0\t1: 6.720 4280.7\t\n",
      "tensor([1.6493e-01, 1.3384e-01, 1.3765e-01, 4.7409e-01, 1.0545e-01, 9.3961e-02,\n",
      "        4.4909e-01, 1.9051e-02, 1.7312e-01, 2.7918e-04, 5.9525e-02, 3.4146e-01,\n",
      "        2.2217e-01, 1.6740e-01, 6.2222e-03, 2.0824e-01])\n",
      "-1: 159.161 170901536.0\t0: 26.871 43918.7\t1: 6.612 3968.4\t\n",
      "tensor([0.1568, 0.0681, 0.1479, 0.6173, 0.0977, 0.1499, 0.7675, 0.0848, 0.2809,\n",
      "        0.0112, 0.0557, 0.7066, 0.1863, 0.1595, 0.0343, 0.1781])\n",
      "-1: 159.142 180365744.0\t0: 27.298 35348.1\t1: 8.224 10890.7\t\n",
      "tensor([0.2903, 0.1821, 0.1856, 0.4476, 0.0565, 0.0871, 0.4194, 0.2520, 0.1980,\n",
      "        0.0814, 0.0953, 0.4902, 0.4025, 0.2872, 0.0610, 0.2986])\n",
      "-1: 159.644 196373520.0\t0: 27.054 41339.4\t1: 9.657 12177.5\t\n",
      "tensor([0.1860, 0.0916, 0.1433, 0.8042, 0.1151, 0.1246, 0.5407, 0.0381, 0.2492,\n",
      "        0.0176, 0.0668, 0.4327, 0.2512, 0.2762, 0.0011, 0.3075])\n",
      "-1: 158.982 214743888.0\t0: 24.798 34700.5\t1: 9.865 13493.5\t\n",
      "tensor([2.1558e-01, 1.7140e-01, 7.6954e-02, 5.3181e-01, 3.2694e-02, 1.1026e-01,\n",
      "        4.7580e-01, 8.5917e-03, 2.2814e-01, 1.3573e-04, 3.4853e-02, 4.3851e-01,\n",
      "        5.7430e-02, 2.0369e-01, 5.2342e-03, 3.1238e-01])\n",
      "-1: 160.384 229413648.0\t0: 26.292 47492.8\t1: 6.156 2825.8\t\n",
      "tensor([0.2156, 0.1069, 0.1747, 0.6995, 0.0707, 0.0980, 0.7141, 0.0519, 0.1529,\n",
      "        0.0071, 0.0733, 0.6958, 0.0497, 0.1736, 0.0182, 0.2120])\n",
      "-1: 161.411 255024944.0\t0: 26.138 39776.2\t1: 9.323 11299.9\t\n",
      "tensor([1.3271e-01, 1.3637e-01, 2.0396e-01, 7.6897e-01, 7.8484e-02, 6.1150e-02,\n",
      "        4.2178e-01, 1.2329e-02, 1.9495e-01, 5.5356e-04, 1.2038e-01, 4.7477e-01,\n",
      "        8.1552e-02, 1.8534e-01, 2.4146e-03, 1.9449e-01])\n",
      "-1: 160.656 274996096.0\t0: 27.312 57211.7\t1: 7.446 3342.9\t\n",
      "tensor([0.1158, 0.1108, 0.2525, 0.9009, 0.0560, 0.0919, 0.7580, 0.0299, 0.2869,\n",
      "        0.0043, 0.1157, 0.6147, 0.1699, 0.2574, 0.0027, 0.4704])\n",
      "-1: 162.170 299929472.0\t0: 26.224 41698.3\t1: 9.986 15437.3\t\n",
      "tensor([0.1561, 0.0976, 0.1827, 0.7559, 0.0708, 0.1330, 0.6476, 0.0116, 0.1465,\n",
      "        0.0031, 0.0972, 0.4910, 0.1004, 0.2327, 0.0067, 0.2739])\n",
      "-1: 162.445 324781632.0\t0: 26.017 29730.2\t1: 8.032 9782.3\t\n",
      "tensor([0.1200, 0.1037, 0.0525, 0.6728, 0.1033, 0.1111, 0.3945, 0.1057, 0.2321,\n",
      "        0.0155, 0.1300, 0.6135, 0.1380, 0.1128, 0.0087, 0.2394])\n",
      "-1: 162.668 355610112.0\t0: 25.364 42313.6\t1: 9.013 9514.2\t\n",
      "tensor([0.2541, 0.2203, 0.1816, 0.5876, 0.0243, 0.1267, 0.5544, 0.0044, 0.2100,\n",
      "        0.0008, 0.1081, 0.5557, 0.0686, 0.2638, 0.0054, 0.1495])\n",
      "-1: 162.602 375672032.0\t0: 26.934 34595.0\t1: 6.574 3859.7\t\n",
      "tensor([0.2183, 0.1436, 0.1419, 0.6625, 0.0450, 0.1309, 0.6595, 0.3062, 0.2510,\n",
      "        0.0491, 0.0509, 0.5238, 0.2387, 0.2165, 0.0438, 0.1197])\n",
      "-1: 162.307 394210592.0\t0: 25.128 47239.4\t1: 8.888 8580.3\t\n",
      "tensor([0.1348, 0.0986, 0.1103, 0.4239, 0.0060, 0.0957, 0.6662, 0.0073, 0.2643,\n",
      "        0.0000, 0.0601, 0.6878, 0.0532, 0.2206, 0.0061, 0.3490])\n",
      "-1: 163.598 432709504.0\t0: 26.603 39558.4\t1: 11.097 26680.1\t\n",
      "tensor([0.1595, 0.1824, 0.1026, 0.7983, 0.0184, 0.1402, 0.5145, 0.3192, 0.2512,\n",
      "        0.0532, 0.0639, 0.5711, 0.1124, 0.2156, 0.0260, 0.1986])\n",
      "-1: 163.654 458353024.0\t0: 24.860 26652.7\t1: 8.856 15236.2\t\n",
      "tensor([0.1935, 0.1172, 0.1677, 0.5147, 0.0961, 0.1302, 0.4993, 0.0331, 0.1444,\n",
      "        0.0009, 0.0795, 0.3754, 0.0759, 0.1746, 0.0026, 0.2127])\n",
      "-1: 162.041 481387264.0\t0: 26.858 40042.5\t1: 8.017 9695.0\t\n",
      "tensor([0.1994, 0.1294, 0.0568, 0.8147, 0.1738, 0.1651, 0.5329, 0.2580, 0.2324,\n",
      "        0.0236, 0.0756, 0.4502, 0.1433, 0.1118, 0.0344, 0.1338])\n",
      "-1: 164.377 520427808.0\t0: 26.379 40090.9\t1: 8.210 10809.1\t\n",
      "tensor([0.1259, 0.1259, 0.1139, 0.6899, 0.0621, 0.1031, 0.4542, 0.0491, 0.2776,\n",
      "        0.0103, 0.0820, 0.6730, 0.0895, 0.1557, 0.0080, 0.2985])\n",
      "-1: 164.109 560295104.0\t0: 26.589 43752.9\t1: 9.514 12564.5\t\n",
      "tensor([0.2508, 0.1297, 0.1138, 0.8813, 0.0428, 0.0966, 0.3874, 0.0299, 0.2066,\n",
      "        0.0010, 0.1146, 0.6705, 0.0685, 0.2257, 0.0212, 0.2535])\n",
      "-1: 165.467 596878144.0\t0: 23.626 34817.9\t1: 8.400 6075.5\t\n",
      "tensor([1.0083e-01, 2.5146e-01, 7.3957e-02, 4.9941e-01, 3.6017e-02, 1.0326e-01,\n",
      "        5.6425e-01, 3.0637e-02, 3.2617e-01, 0.0000e+00, 3.8364e-02, 4.1387e-01,\n",
      "        8.9258e-02, 2.4796e-01, 1.2963e-05, 1.1583e-01])\n",
      "-1: 165.583 646501888.0\t0: 26.763 41756.8\t1: 9.778 14330.4\t\n",
      "tensor([0.2405, 0.0755, 0.1273, 0.6242, 0.0695, 0.0670, 0.4161, 0.0587, 0.3820,\n",
      "        0.0076, 0.1312, 0.3947, 0.2569, 0.2861, 0.0267, 0.2890])\n",
      "-1: 165.901 679105792.0\t0: 26.917 39492.3\t1: 11.575 32842.0\t\n",
      "tensor([0.2897, 0.1587, 0.1596, 0.8431, 0.0236, 0.1142, 0.5983, 0.0843, 0.1680,\n",
      "        0.0050, 0.0757, 0.5287, 0.3618, 0.2093, 0.0069, 0.1480])\n",
      "-1: 166.509 758272704.0\t0: 24.894 27955.4\t1: 8.918 8948.8\t\n",
      "tensor([0.1812, 0.1072, 0.1172, 0.5226, 0.0626, 0.0781, 0.5328, 0.0127, 0.1690,\n",
      "        0.0000, 0.0487, 0.3653, 0.3521, 0.3072, 0.0078, 0.1509])\n",
      "-1: 166.636 795359232.0\t0: 25.059 44558.2\t1: 10.208 15802.5\t\n",
      "tensor([0.3010, 0.0715, 0.1141, 0.8257, 0.0918, 0.0428, 0.6350, 0.0023, 0.1433,\n",
      "        0.0000, 0.0717, 0.6129, 0.0901, 0.2818, 0.0102, 0.1479])\n",
      "-1: 166.679 825013632.0\t0: 25.321 35978.2\t1: 5.549 1713.3\t\n",
      "tensor([0.1375, 0.1370, 0.1894, 0.6815, 0.1240, 0.0504, 0.6752, 0.0076, 0.3335,\n",
      "        0.0000, 0.0730, 0.4390, 0.0618, 0.2517, 0.0087, 0.2488])\n",
      "-1: 166.893 893775552.0\t0: 24.360 43019.8\t1: 8.261 11115.6\t\n",
      "tensor([1.9785e-01, 1.3377e-01, 1.2925e-01, 8.0580e-01, 5.7197e-02, 1.4312e-01,\n",
      "        6.3221e-01, 1.1734e-02, 1.3533e-01, 3.7024e-03, 2.8218e-02, 4.9974e-01,\n",
      "        2.0366e-01, 1.7590e-01, 3.7361e-06, 2.1578e-01])\n",
      "-1: 167.526 937858304.0\t0: 25.340 37683.7\t1: 8.900 15582.2\t\n",
      "tensor([0.1811, 0.1847, 0.0932, 0.5981, 0.0490, 0.1099, 0.6790, 0.0230, 0.2551,\n",
      "        0.0000, 0.0660, 0.5054, 0.0930, 0.2692, 0.0091, 0.3135])\n",
      "-1: 168.351 1012896960.0\t0: 25.848 33869.0\t1: 11.517 31028.9\t\n",
      "tensor([0.0951, 0.0784, 0.0666, 0.7144, 0.0490, 0.1058, 0.5514, 0.0624, 0.1453,\n",
      "        0.0026, 0.0272, 0.4997, 0.2143, 0.2287, 0.0079, 0.2796])\n",
      "-1: 167.992 1058431872.0\t0: 24.797 24837.4\t1: 8.871 15348.4\t\n",
      "tensor([0.1411, 0.1382, 0.1453, 0.3747, 0.0167, 0.1089, 0.5609, 0.0229, 0.2128,\n",
      "        0.0010, 0.0321, 0.5511, 0.1590, 0.2405, 0.0135, 0.2321])\n",
      "-1: 168.851 1131974400.0\t0: 24.675 48623.4\t1: 10.336 19190.0\t\n",
      "tensor([0.3728, 0.1025, 0.1004, 1.0347, 0.0562, 0.1044, 0.4295, 0.0000, 0.2572,\n",
      "        0.0000, 0.1477, 0.4618, 0.1298, 0.3110, 0.0014, 0.1390])\n",
      "-1: 168.970 1128463488.0\t0: 24.673 38953.6\t1: 8.235 10957.4\t\n",
      "tensor([2.7226e-01, 1.6128e-01, 2.1674e-01, 8.2681e-01, 5.1649e-02, 9.8014e-02,\n",
      "        4.8765e-01, 3.7997e-04, 1.5454e-01, 0.0000e+00, 5.7921e-02, 7.1776e-01,\n",
      "        2.2737e-01, 2.2312e-01, 1.0343e-02, 1.9775e-01])\n",
      "\n",
      "Average loss: 0.0062, Accuracy: 209/450 (46.44%), -1: 148.719 10423735.0\t0: 32.377 3135650.2\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 233/450 (51.78%), -1: 148.409 10251486.0\t0: 32.344 2162105.8\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 259/450 (57.56%), -1: 147.891 10189595.0\t0: 32.761 2566027.0\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 273/450 (60.67%), -1: 147.867 10141287.0\t0: 32.486 2364650.2\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 281/450 (62.44%), -1: 149.251 10899010.0\t0: 32.709 2399848.8\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 300/450 (66.67%), -1: 149.016 10892312.0\t0: 31.778 2388754.2\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 314/450 (69.78%), -1: 150.534 11735671.0\t0: 31.988 1803411.8\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 330/450 (73.33%), -1: 150.002 11887838.0\t0: 32.456 2285167.8\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 340/450 (75.56%), -1: 149.486 11820997.0\t0: 31.547 1582788.6\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 339/450 (75.33%), -1: 150.674 13806955.0\t0: 30.613 1539247.1\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 348/450 (77.33%), -1: 151.141 14841173.0\t0: 30.304 1193203.5\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 372/450 (82.67%), -1: 150.927 15424558.0\t0: 30.852 999618.0\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 396/450 (88.00%), -1: 151.435 17031724.0\t0: 30.773 1156556.1\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 378/450 (84.00%), -1: 151.813 18347412.0\t0: 31.164 1237149.6\t1: 1.115 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 391/450 (86.89%), -1: 151.892 21384204.0\t0: 30.542 804684.2\t1: 0.000 0.5\t\n",
      "Average loss: 0.0062, Accuracy: 387/450 (86.00%), -1: 151.798 21959866.0\t0: 31.334 1305762.5\t1: 0.000 0.5\t\n",
      "Average loss: 0.0061, Accuracy: 393/450 (87.33%), -1: 152.408 26439642.0\t0: 31.832 842940.2\t1: 0.000 0.5\t\n",
      "Average loss: 0.0061, Accuracy: 391/450 (86.89%), -1: 152.961 29848236.0\t0: 30.727 615699.8\t1: 0.000 0.5\t\n",
      "Average loss: 0.0061, Accuracy: 399/450 (88.67%), -1: 153.200 31798596.0\t0: 29.638 542488.3\t1: 0.000 0.5\t\n",
      "Average loss: 0.0060, Accuracy: 408/450 (90.67%), -1: 155.037 40999084.0\t0: 29.277 392152.7\t1: 1.591 0.5\t\n",
      "Average loss: 0.0060, Accuracy: 408/450 (90.67%), -1: 153.093 42067860.0\t0: 29.719 497545.2\t1: 0.000 0.5\t\n",
      "Average loss: 0.0060, Accuracy: 399/450 (88.67%), -1: 153.439 44135176.0\t0: 29.616 343160.3\t1: 4.536 131.0\t\n",
      "Average loss: 0.0059, Accuracy: 411/450 (91.33%), -1: 154.947 50309412.0\t0: 30.381 326271.9\t1: 1.190 0.5\t\n",
      "Average loss: 0.0059, Accuracy: 412/450 (91.56%), -1: 154.820 55170220.0\t0: 28.359 237981.8\t1: 1.042 0.5\t\n",
      "Average loss: 0.0060, Accuracy: 409/450 (90.89%), -1: 156.003 62129784.0\t0: 29.419 420578.0\t1: 3.949 302.3\t\n",
      "Average loss: 0.0059, Accuracy: 397/450 (88.22%), -1: 156.349 71046024.0\t0: 29.339 276497.9\t1: 0.000 0.5\t\n",
      "Average loss: 0.0057, Accuracy: 402/450 (89.33%), -1: 157.322 80550656.0\t0: 29.233 236570.9\t1: 0.000 0.5\t\n",
      "Average loss: 0.0056, Accuracy: 396/450 (88.00%), -1: 156.673 88990600.0\t0: 28.551 258867.4\t1: 1.139 0.5\t\n",
      "Average loss: 0.0055, Accuracy: 399/450 (88.67%), -1: 156.879 94666440.0\t0: 29.711 234051.8\t1: 2.177 0.5\t\n",
      "Average loss: 0.0053, Accuracy: 411/450 (91.33%), -1: 157.146 105442480.0\t0: 29.481 198484.7\t1: 0.000 0.5\t\n",
      "Average loss: 0.0052, Accuracy: 407/450 (90.44%), -1: 157.632 116982416.0\t0: 28.158 175227.3\t1: 1.114 0.5\t\n",
      "Average loss: 0.0049, Accuracy: 404/450 (89.78%), -1: 158.926 137676336.0\t0: 29.166 119039.9\t1: 0.000 0.5\t\n",
      "Average loss: 0.0051, Accuracy: 400/450 (88.89%), -1: 158.328 141670736.0\t0: 28.831 155089.4\t1: 2.306 11.4\t\n",
      "Average loss: 0.0049, Accuracy: 408/450 (90.67%), -1: 158.821 151743648.0\t0: 28.649 99372.0\t1: 5.326 1401.3\t\n",
      "Average loss: 0.0048, Accuracy: 414/450 (92.00%), -1: 158.544 167613536.0\t0: 27.676 111602.1\t1: 0.000 0.5\t\n",
      "Average loss: 0.0046, Accuracy: 415/450 (92.22%), -1: 158.580 184513568.0\t0: 28.663 98265.6\t1: 1.125 0.5\t\n",
      "Average loss: 0.0044, Accuracy: 410/450 (91.11%), -1: 160.527 203497664.0\t0: 29.145 134347.9\t1: 2.727 35.4\t\n",
      "Average loss: 0.0040, Accuracy: 416/450 (92.44%), -1: 159.361 209677664.0\t0: 28.980 94623.6\t1: 3.064 3.0\t\n",
      "Average loss: 0.0042, Accuracy: 421/450 (93.56%), -1: 160.276 226310704.0\t0: 28.276 55576.9\t1: 6.554 3806.4\t\n",
      "Average loss: 0.0036, Accuracy: 423/450 (94.00%), -1: 160.156 249910032.0\t0: 27.882 43789.4\t1: 4.888 913.4\t\n",
      "Average loss: 0.0037, Accuracy: 420/450 (93.33%), -1: 159.968 263613392.0\t0: 27.421 45973.9\t1: 4.578 655.1\t\n",
      "Average loss: 0.0033, Accuracy: 431/450 (95.78%), -1: 161.376 282079488.0\t0: 27.553 44614.5\t1: 7.962 4367.4\t\n",
      "Average loss: 0.0034, Accuracy: 423/450 (94.00%), -1: 162.617 311986880.0\t0: 28.434 60966.4\t1: 4.585 118.5\t\n",
      "Average loss: 0.0028, Accuracy: 433/450 (96.22%), -1: 162.606 373790368.0\t0: 26.743 26608.2\t1: 8.551 7293.2\t\n",
      "Average loss: 0.0027, Accuracy: 436/450 (96.89%), -1: 162.986 355444096.0\t0: 27.495 34833.2\t1: 4.124 380.6\t\n",
      "Average loss: 0.0024, Accuracy: 424/450 (94.22%), -1: 162.508 397887808.0\t0: 27.013 24098.2\t1: 9.052 9367.9\t\n",
      "Average loss: 0.0022, Accuracy: 429/450 (95.33%), -1: 163.265 424372768.0\t0: 26.771 23263.2\t1: 5.244 1297.9\t\n",
      "Average loss: 0.0020, Accuracy: 441/450 (98.00%), -1: 164.400 457249504.0\t0: 27.567 33898.3\t1: 8.420 12124.5\t\n",
      "Average loss: 0.0020, Accuracy: 435/450 (96.67%), -1: 161.861 497601024.0\t0: 27.802 36335.2\t1: 5.094 1123.0\t\n",
      "Average loss: 0.0016, Accuracy: 440/450 (97.78%), -1: 163.733 535948128.0\t0: 26.174 20298.3\t1: 8.259 5225.8\t\n",
      "Average loss: 0.0016, Accuracy: 437/450 (97.11%), -1: 164.295 568099328.0\t0: 26.578 23815.8\t1: 6.686 4168.8\t\n",
      "Average loss: 0.0014, Accuracy: 443/450 (98.44%), -1: 164.040 590890944.0\t0: 27.128 23427.3\t1: 5.666 1895.5\t\n",
      "Average loss: 0.0013, Accuracy: 448/450 (99.56%), -1: 166.496 668868032.0\t0: 26.890 25318.3\t1: 8.413 12076.7\t\n",
      "Average loss: 0.0011, Accuracy: 445/450 (98.89%), -1: 165.627 648261440.0\t0: 26.136 19443.9\t1: 6.587 3897.1\t\n",
      "Average loss: 0.0009, Accuracy: 446/450 (99.11%), -1: 166.249 743672256.0\t0: 26.088 22880.4\t1: 6.309 3173.0\t\n",
      "Average loss: 0.0009, Accuracy: 449/450 (99.78%), -1: 166.429 782868928.0\t0: 26.961 27678.5\t1: 7.489 7093.9\t\n",
      "Average loss: 0.0008, Accuracy: 447/450 (99.33%), -1: 167.113 846389760.0\t0: 26.315 32405.2\t1: 8.635 13594.9\t\n",
      "Average loss: 0.0007, Accuracy: 448/450 (99.56%), -1: 167.469 900656960.0\t0: 26.969 31297.8\t1: 10.062 16372.7\t\n",
      "Average loss: 0.0006, Accuracy: 447/450 (99.33%), -1: 167.688 955733696.0\t0: 26.251 45220.6\t1: 11.042 24129.5\t\n",
      "Average loss: 0.0006, Accuracy: 447/450 (99.33%), -1: 167.760 969714496.0\t0: 26.008 24010.2\t1: 8.218 10856.1\t\n",
      "Average loss: 0.0004, Accuracy: 449/450 (99.78%), -1: 169.133 1073831808.0\t0: 24.992 28264.5\t1: 10.702 21543.3\t\n",
      "Average loss: 0.0002, Accuracy: 450/450 (100.00%), -1: 167.600 1115575040.0\t0: 24.945 32984.2\t1: 9.301 10776.8\t\n",
      "Average loss: 0.0003, Accuracy: 450/450 (100.00%), -1: 169.452 1230592000.0\t0: 22.315 44211.7\t1: 10.125 17326.9\t\n"
     ]
    }
   ],
   "source": [
    "for key, value in model.activations.items():\n",
    "    print(\"{}: {:.3f} {}\".format(key, effective_rank(value, partial=True).item(), round(orthogonality_gap(value).item(), 1)), end=\"\\t\")\n",
    "print()\n",
    "print(activation_variance(model.activations[\"0\"]))\n",
    "\n",
    "for power in range(int(math.log(base_data.input_dim, 2))):\n",
    "    mod = copy.deepcopy(model)\n",
    "    mod_optimizer = torch.optim.SGD(mod.parameters(), lr=0.01)\n",
    "    mod_optimizer.load_state_dict(optimizer.state_dict())\n",
    "\n",
    "    shift = 2**(int(math.log(base_data.input_dim, 2))-power-1)\n",
    "    datasets = [val_loader]\n",
    "    \n",
    "    print(\"Training {} epochs per shift, shifting window by {} indices {} times\".format(64//int(base_data.input_dim/shift), shift, int(base_data.input_dim/shift)))\n",
    "    for step in range(int(base_data.input_dim/shift)-2):\n",
    "        modded_data = copy.deepcopy(base_data)\n",
    "        modded_data.shift_distribution(adder=((step+1)*shift)/32)\n",
    "        modded_train_loader, modded_val_loader, modded_test_loader = split_dataset(modded_data, val_size = 0.1, test_size = 0.1, batch_size = 128)\n",
    "        datasets.append(modded_val_loader)\n",
    "        train(mod, modded_train_loader, mod_optimizer, criterion, epochs=64//int(base_data.input_dim/shift), val_loader=modded_val_loader, device=device, regression=regression, verbose=False, val_verbose=False)\n",
    "        for key, value in mod.activations.items():\n",
    "            print(\"{}: {:.3f} {}\".format(key, effective_rank(value, partial=True).item(), round(orthogonality_gap(value).item(), 1)), end=\"\\t\")\n",
    "        print()\n",
    "        print(activation_variance(mod.activations[\"0\"]))\n",
    "    print()\n",
    "    for vl in datasets:\n",
    "        test(mod, vl, criterion, device=device, regression=regression, metrics=True)\n",
    "        print(\", \", end=\"\")\n",
    "        for key, value in mod.activations.items():\n",
    "            print(\"{}: {:.3f} {}\".format(key, effective_rank(value, partial=True).item(), round(orthogonality_gap(value).item(), 1)), end=\"\\t\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#track and plot neuron-wise scores across distribution shifts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17b88845c8368f4e9bf0ab0c6bd871dae3b65fc6e015c8990d2b5b0cf4897a6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
