{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lt0zLa_1Gf5_"
   },
   "source": [
    "\n",
    "# Local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kQvA8zzt-lWl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet -r ../requirements.txt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.expanduser(\"~/repos/NeurOps/pytorch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwWhZkHUGbZw"
   },
   "source": [
    "# Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmkB9LAt-m_6",
    "outputId": "6866f729-d6a7-4938-d417-382fab648ff8"
   },
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/SuReLI/NeurOps.git\n",
    "# ! git clone https://github.com/k8lion/GrowAndPrune.git\n",
    "# %cd GrowAndPrune\n",
    "# ! git pull\n",
    "# %cd src\n",
    "# ! pip install --quiet -r ../requirements.txt\n",
    "# ! mkdir ../../data\n",
    "# ! wget -O ../../data/Galaxy10_DECals.h5 wget https://astro.utoronto.ca/~hleung/shared/Galaxy10/Galaxy10_DECals.h5\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(\"../../NeurOps/pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amnEvhqoGpB4"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K0AKgP15-lWr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaitlin/repos/GrowAndPrune/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/kaitlin/repos/GrowAndPrune/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from celluloid import Camera\n",
    "from IPython.display import HTML\n",
    "from collections import OrderedDict\n",
    "\n",
    "from neurops import *\n",
    "\n",
    "from growprune import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget -O ../../data/vgg11-8a719046.pth https://download.pytorch.org/models/vgg11-8a719046.pth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_linear = True\n",
    "limit = 15 if not copy_linear else 19\n",
    "model = ModVGG11(num_classes=10, avgpooldim=7).to(device)\n",
    "weights = torch.load(\"../../data/vgg11-8a719046.pth\")\n",
    "renamed = OrderedDict()\n",
    "for i, (key, value) in enumerate(zip(model.state_dict(), weights.values())):\n",
    "    if i <= limit:\n",
    "        renamed[key] = value\n",
    "    else:\n",
    "        renamed[key] = model.state_dict()[key]\n",
    "model.load_state_dict(renamed)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, validation_loader, test_loader = get_galaxy10_dataloaders(path_to_dir=\"../..\", batch_size=-1, dim=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = torch.randn(1, 3, 64, 64).to(device)\n",
    "# for layer in model:\n",
    "#     test = layer(test)\n",
    "#     print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.0075, Accuracy: 160/15963 (1.00%)\n",
      "torch.Size([1605632, 64])\n",
      "Layer 0 has effective rank 64.0\n",
      "torch.Size([802816, 128])\n",
      "Layer 1 has effective rank 126.0\n",
      "torch.Size([1605632, 256])\n",
      "Layer 2 has effective rank 253.0\n",
      "torch.Size([401408, 256])\n",
      "Layer 3 has effective rank 256.0\n",
      "torch.Size([802816, 512])\n",
      "Layer 4 has effective rank 511.0\n",
      "torch.Size([200704, 512])\n",
      "Layer 5 has effective rank 504.0\n",
      "torch.Size([200704, 512])\n",
      "Layer 6 has effective rank 507.0\n",
      "torch.Size([50176, 512])\n",
      "Layer 7 has effective rank 484.0\n",
      "torch.Size([1596, 4096])\n",
      "Layer 8 has effective rank 1596.0\n",
      "torch.Size([1596, 4096])\n",
      "Layer 9 has effective rank 1537.0\n",
      "Train Epoch: 0 [0/15963 (0%)]\tLoss: 2.368692\n",
      "Train Epoch: 0 [3200/15963 (22%)]\tLoss: 1.115528\n"
     ]
    }
   ],
   "source": [
    "test(model, validation_loader, criterion, device=device)\n",
    "init_score = np.zeros(len(model.activations))\n",
    "for i in range(len(model)-1):\n",
    "    tensor = model.activations[str(i)]\n",
    "    print(torch.transpose(torch.transpose(tensor, 0, 1).reshape(tensor.shape[1], -1), 0, 1).shape)\n",
    "    init_score[i] = effective_rank(model.activations[str(i)], limit_ratio = 10)\n",
    "    print(f\"Layer {i} has effective rank {init_score[i]}\")\n",
    "\n",
    "train(model, train_loader, optimizer, criterion, epochs=1, val_loader=validation_loader, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 2498119335936 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m score \u001b[39m=\u001b[39m effective_rank(modded_model_grow\u001b[39m.\u001b[39mactivations[\u001b[39mstr\u001b[39m(i)], limit_ratio \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m)\n\u001b[1;32m     12\u001b[0m num_to_prune \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mint\u001b[39m(\u001b[39m0.9\u001b[39m\u001b[39m*\u001b[39minit_score[i])\u001b[39m-\u001b[39mscore, \u001b[39m0\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m scores \u001b[39m=\u001b[39m svd_score(modded_model_grow\u001b[39m.\u001b[39;49mactivations[\u001b[39mstr\u001b[39;49m(i)])\n\u001b[1;32m     14\u001b[0m to_prune \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(scores\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())[:num_to_prune]\n\u001b[1;32m     15\u001b[0m to_add \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(score\u001b[39m-\u001b[39m\u001b[39mint\u001b[39m(\u001b[39m0.97\u001b[39m\u001b[39m*\u001b[39minit_score[i]), \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/repos/NeurOps/pytorch/neurops/metrics.py:91\u001b[0m, in \u001b[0;36msvd_score\u001b[0;34m(tensor, threshold, addwhole, scale, difference)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m scale:\n\u001b[1;32m     90\u001b[0m     prunedtensor \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m prunedtensor\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m\n\u001b[0;32m---> 91\u001b[0m _, S, _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msvd(prunedtensor, compute_uv\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     92\u001b[0m effdim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(S)\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m addwhole:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 2498119335936 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "#modded_model_grow = copy.deepcopy(model)\n",
    "#modded_optimizer_grow = torch.optim.SGD(modded_model_grow.parameters(), lr=0.01)\n",
    "#modded_optimizer_grow.load_state_dict(optimizer.state_dict())\n",
    "\n",
    "modded_model_grow = model\n",
    "modded_optimizer_grow = optimizer\n",
    "\n",
    "for iter in range(5):\n",
    "    for i in range(len(modded_model_grow)-1):\n",
    "        max_rank = modded_model_grow[i].out_features if i > modded_model_grow.conversion_layer else modded_model_grow[i].out_channels\n",
    "        score = effective_rank(modded_model_grow.activations[str(i)], limit_ratio = 100)\n",
    "        num_to_prune = max(int(0.9*init_score[i])-score, 0)\n",
    "        scores = svd_score(modded_model_grow.activations[str(i)], limit_ratio = 100)\n",
    "        to_prune = np.argsort(scores.cpu().detach().numpy())[:num_to_prune]\n",
    "        to_add = max(score-int(0.97*init_score[i]), 0)\n",
    "        print(\"Layer {} score: {}/{}, neurons to prune: {}, # neurons to add: {}\".format(i, score, max_rank, to_prune, to_add))\n",
    "        modded_model_grow.prune(i, to_prune, optimizer=modded_optimizer_grow)\n",
    "        modded_model_grow.grow(i, to_add, fanin_weights=\"iterative_orthogonalization\", \n",
    "                               optimizer=modded_optimizer_grow)\n",
    "    print(\"The modded model now has {} effective parameters.\".format(modded_model_grow.parameter_count(masked = True)))\n",
    "    print(\"Validation after growing: \", end = \"\")\n",
    "    test(modded_model_grow, validation_loader, criterion, device=device)\n",
    "    train(modded_model_grow, train_loader, modded_optimizer_grow, criterion, epochs=2, val_loader=validation_loader, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2eb92184efe66b42aa15387d477792c03980dca2132a89a8dd7cfbda87719ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
